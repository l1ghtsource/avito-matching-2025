{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60d1a1de-78cf-479e-82bd-6adf79eae63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "import cv2\n",
    "import os\n",
    "import swifter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import precision_recall_curve, auc, average_precision_score\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import glob\n",
    "import random\n",
    "from gc import collect as garbage_collector\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99616802-378a-48be-b781-1b317838363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrunkModel(nn.Module):\n",
    "    def __init__(self, model_name,):\n",
    "        super().__init__()\n",
    "        self.trunk_model = timm.create_model(\n",
    "            model_name=model_name,\n",
    "            pretrained=True,\n",
    "            num_classes=0\n",
    "        )\n",
    "        \n",
    "        #self.__delete_mlp_head()\n",
    "        print('----TRUNK----')\n",
    "        print(self.trunk_model)\n",
    "\n",
    "    def __delete_mlp_head(self):\n",
    "        model_layers = list(self.trunk_model.named_modules())\n",
    "        mlp_layer_name = None\n",
    "        for i, (name, module) in enumerate(model_layers):\n",
    "            if isinstance(module, nn.Linear):\n",
    "                mlp_layer_name = name\n",
    "                mlp_module_in_features = module.in_features\n",
    "                break\n",
    "\n",
    "        self.mlp_module_in_features = mlp_module_in_features\n",
    "\n",
    "        delattr(self.trunk_model, mlp_layer_name)\n",
    "        \n",
    "        print(\n",
    "            \"MLP head was deleted\"\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.trunk_model(x)\n",
    "\n",
    "\n",
    "class HeadModel(nn.Module):\n",
    "    def __init__(self, mlp_architecture):\n",
    "        super().__init__()\n",
    "        self.head = nn.Sequential(*mlp_architecture)\n",
    "        self._init_params()\n",
    "        print('----HEAD----')\n",
    "        print(self.head)\n",
    "        \n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.head[0].weight)\n",
    "        nn.init.constant_(self.head[0].bias, 0)\n",
    "        nn.init.constant_(self.head[1].weight, 1)\n",
    "        nn.init.constant_(self.head[1].bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.head(x)\n",
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, trunk, head):\n",
    "        super().__init__()\n",
    "        self.trunk = trunk\n",
    "        self.head = head\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.trunk(x)\n",
    "        x = self.head(x)\n",
    "        return F.normalize(x)\n",
    "\n",
    "class KakUchitToBlya(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, transforms, path_to_images):\n",
    "        self.data = self.create_image_names_pairs(dataframe)\n",
    "        self.transforms = transforms\n",
    "        self.path = path_to_images\n",
    "            \n",
    "    @staticmethod\n",
    "    def create_image_names_pairs(df):\n",
    "        return list(zip(df.variantid_1, df.variantid_2, df.base_title_image, df.cand_title_image, df.is_double))\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id1, id2, img1, img2, target = self.data[idx]\n",
    "        \n",
    "        try:\n",
    "            image1 = cv2.imread(self.path + img1 + '.jpg')\n",
    "            image2 = cv2.imread(self.path + img2 + '.jpg')\n",
    "    \n",
    "            image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
    "            image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if self.transforms:\n",
    "                image1 = self.transforms(image=image1)['image']\n",
    "                image2 = self.transforms(image=image2)['image']\n",
    "        except:\n",
    "            image1 = torch.zeros((3, IMG_SIZE, IMG_SIZE))\n",
    "            image2 = torch.zeros((3, IMG_SIZE, IMG_SIZE))\n",
    "            target = 255\n",
    "        \n",
    "        return {\n",
    "            \"image1\": image1,\n",
    "            \"image2\": image2,\n",
    "            \"id1\": id1,\n",
    "            \"id2\": id2,\n",
    "            \"labels\": torch.tensor(target, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class OnlineContrastiveLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self, margin: float = 0.5, strategy='online'\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        self.distance_metric = lambda x, y: 1 - F.cosine_similarity(x, y)\n",
    "        self.strategy = strategy\n",
    "        \n",
    "    def forward(self, embedding1, embedding2, labels, size_average=True):\n",
    "\n",
    "        mask = labels != 255\n",
    "        labels = labels[mask]\n",
    "        embedding1 = embedding1[mask]\n",
    "        embedding2 = embedding2[mask]\n",
    "        \n",
    "        \n",
    "        distance_matrix = self.distance_metric(embedding1, embedding2)\n",
    "        \n",
    "        if self.strategy == 'online':\n",
    "            negs = distance_matrix[labels == 0]\n",
    "            poss = distance_matrix[labels == 1]\n",
    "        \n",
    "            negative_pairs = negs[negs < (poss.max() if len(poss) > 1 else negs.mean())]\n",
    "            positive_pairs = poss[poss > (negs.min() if len(negs) > 1 else poss.mean())]\n",
    "    \n",
    "            positive_loss = positive_pairs.pow(2).sum()\n",
    "            negative_loss = F.relu(self.margin - negative_pairs).pow(2).sum()\n",
    "            loss = positive_loss + negative_loss\n",
    "            if size_average:\n",
    "                loss /= (len(negative_pairs) + len(positive_pairs) + 1e-8)\n",
    "            return loss\n",
    "        elif self.strategy == 'common':\n",
    "            losses = 0.5 * (\n",
    "            labels.float() * distance_matrix.pow(2) + (1 - labels).float() * F.relu(self.margin - distance_matrix).pow(2)\n",
    "        )\n",
    "            return losses.mean() if size_average else losses.sum()\n",
    "        elif self.strategy == 'combined':\n",
    "            negs = distance_matrix[labels == 0]\n",
    "            poss = distance_matrix[labels == 1]\n",
    "        \n",
    "            negative_pairs = negs[negs < (poss.max() if len(poss) > 1 else negs.mean())]\n",
    "            positive_pairs = poss[poss > (negs.min() if len(negs) > 1 else poss.mean())]\n",
    "    \n",
    "            positive_loss = positive_pairs.pow(2).sum()\n",
    "            negative_loss = F.relu(self.margin - negative_pairs).pow(2).sum()\n",
    "            loss = positive_loss + negative_loss\n",
    "            loss /= (len(negative_pairs) + len(positive_pairs) + 1e-8)\n",
    "            \n",
    "            losses = 0.5 * (\n",
    "            labels.float() * distance_matrix.pow(2) + (1 - labels).float() * F.relu(self.margin - distance_matrix).pow(2)\n",
    "        )\n",
    "            losses = losses.mean()\n",
    "            return (loss + losses) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84435d70-0ea3-453a-a411-88fc5ca5fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_df_from_path(path, columns_for_filter=None):\n",
    "    all_data = []\n",
    "    for parquet in glob.glob(path + '*.parquet'):\n",
    "        all_data.append(\n",
    "            pd.read_parquet(parquet, engine='pyarrow')\n",
    "        )\n",
    "    all_data_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    return all_data_df[columns_for_filter] if columns_for_filter else all_data_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef7764ec-8e48-42b1-af7e-9b9146bbbf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переменные\n",
    "SEED = 1488\n",
    "\n",
    "# ---------МОДЕЛЬ----------\n",
    "MODEL_NAME = 'resnet50.a1_in1k'\n",
    "FC_DIM = 768\n",
    "\n",
    "# ---------ОБУЧЕНИЕ---------\n",
    "N_EPOCH = 1\n",
    "IMG_SIZE = 224\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "CURRENT_FOLD = 1\n",
    "\n",
    "# ---------ДАННЫЕ-----------\n",
    "PATH_TO_TRAIN_PARQUETS = r'C:\\avito\\tables\\train/'\n",
    "PATH_TO_TRAIN_IMAGES = r'C:\\avito\\images\\train\\images/'\n",
    "\n",
    "PATH_TO_TEST_PARQUETS = r'C:\\avito\\tables\\test/'\n",
    "PATH_TO_TEST_IMAGES = r'C:\\avito\\images\\test\\images/'\n",
    "\n",
    "PATH_TO_TXT = './train_images_zip_paths.txt'\n",
    "\n",
    "COLUMNS = ['base_item_id',\n",
    "           'cand_item_id',\n",
    "           'base_subcategory_name',\n",
    "           'cand_subcategory_name',\n",
    "           'group_id', \n",
    "           'action_date', \n",
    "           'base_title_image', \n",
    "           'cand_title_image', \n",
    "           'is_double']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22e407a4-ef65-4eee-aac8-d3efcdd5e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "        #A.HorizontalFlip(),\n",
    "        #A.VerticalFlip(),\n",
    "        #A.Rotate(), \n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d53229fe-21c4-4e91-8728-48b87e854e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_merged_df_from_path(PATH_TO_TRAIN_PARQUETS, COLUMNS).rename(columns={'base_item_id': 'variantid_1', 'cand_item_id': 'variantid_2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a22815d7-ed4c-4709-98e3-40198c0da36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_parquet(\n",
    "#     '/kaggle/input/for-fasttext-and-bert-avito/train_zalupa.parquet',\n",
    "#     columns=['variantid_1', 'variantid_2', 'group_id', 'is_double']\n",
    "# )\n",
    "\n",
    "df = df.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "df = df.sample(len(df), random_state=42)\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=5)\n",
    "\n",
    "fold_mapping = {\n",
    "    '0': {\n",
    "        'train_idxs': [],\n",
    "        'val_idxs': [],\n",
    "    },\n",
    "    '1': {\n",
    "        'train_idxs': [],\n",
    "        'val_idxs': [],\n",
    "    },\n",
    "    '2': {\n",
    "        'train_idxs': [],\n",
    "        'val_idxs': [],\n",
    "    },\n",
    "    '3': {\n",
    "        'train_idxs': [],\n",
    "        'val_idxs': [],\n",
    "    },\n",
    "    '4': {\n",
    "        'train_idxs': [],\n",
    "        'val_idxs': [],\n",
    "    },\n",
    "}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(sgkf.split(df, df['is_double'], groups=df['group_id'])):\n",
    "    fold_mapping[str(fold)]['train_idxs'] = train_idx\n",
    "    fold_mapping[str(fold)]['val_idxs'] = val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e44ddc26-f44c-4179-be27-0aa8a0a295eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet50.a1_in1k)\n",
      "INFO:timm.models._hub:[timm/resnet50.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----TRUNK----\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "----HEAD----\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2048, out_features=768, bias=True)\n",
      "  (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trunk_model = TrunkModel(MODEL_NAME)\n",
    "head_model_architecture = nn.Sequential(\n",
    "        nn.Linear(trunk_model.trunk_model.num_features, FC_DIM),\n",
    "        nn.BatchNorm1d(FC_DIM)\n",
    "       \n",
    ")\n",
    "head_model = HeadModel(head_model_architecture)\n",
    "model = EmbeddingModel(trunk_model, head_model).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "id": "c0f34e3e-db0d-4f43-b609-51932029b52d",
   "metadata": {},
   "source": [
    "oof_preds = np.zeros(len(df))\n",
    "for fold in range(0, 5):\n",
    "\n",
    "    w = load_file(f'./resnet/resnet_fold{fold}.safetensors')\n",
    "\n",
    "    model.load_state_dict(w)\n",
    "    model.eval()\n",
    "    val_idx = fold_mapping[str(fold)]['val_idxs']\n",
    "    val_dataset = KakUchitToBlya(dataframe=df.iloc[val_idx], \n",
    "                                 transforms=test_transforms, \n",
    "                                 path_to_images=PATH_TO_TRAIN_IMAGES)\n",
    "    fold_preds = []\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm(DataLoader(val_dataset, \n",
    "                                      shuffle=False, \n",
    "                                      #pin_memory=True, \n",
    "                                      #num_workers=6, \n",
    "                                      batch_size=1)):\n",
    "            \n",
    "            img1 = inputs.pop('image1').to(DEVICE)\n",
    "            img2 = inputs.pop('image2').to(DEVICE)\n",
    "            labels = inputs.pop('labels').to(DEVICE)\n",
    "\n",
    "            batch = torch.cat([img1, img2], dim=0)\n",
    "            \n",
    "            assert batch.shape[0] % 2 == 0\n",
    "            \n",
    "            outputs = model(batch)\n",
    "    \n",
    "            emb1, emb2 = torch.chunk(outputs, 2)\n",
    "\n",
    "            batch_cossim = F.cosine_similarity(emb1, emb2)\n",
    "            batch_cossim[labels == 255] = np.nan\n",
    "            \n",
    "            fold_preds.extend(\n",
    "                batch_cossim.tolist()\n",
    "            )\n",
    "            \n",
    "    assert len(val_idx) == len(fold_preds)\n",
    "    \n",
    "    oof_preds[val_idx] = fold_preds\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01a30977-d32d-4cbd-baf5-33ba0ef6d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cossims_resnet'] = oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd0b55cf-59c5-480d-b188-5e194a11b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['variantid_1', 'variantid_2', 'cossims_resnet']].to_parquet('./cossim_resnet.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
