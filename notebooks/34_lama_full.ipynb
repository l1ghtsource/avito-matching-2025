{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 7.268081,
     "end_time": "2025-05-03T06:32:40.510251",
     "exception": false,
     "start_time": "2025-05-03T06:32:33.242170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from lightautoml.automl.presets.tabular_presets import (TabularAutoML,\n",
    "                                                        TabularUtilizedAutoML)\n",
    "from lightautoml.report.report_deco import ReportDeco\n",
    "from lightautoml.tasks import Task\n",
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "from sklearn.model_selection import (GroupKFold, GroupShuffleSplit,\n",
    "                                     StratifiedGroupKFold)\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR_PATH = ''\n",
    "\n",
    "MAIN_PATH = Path(f'{ROOT_DIR_PATH}data/avito-merged-dataset')\n",
    "ECOM_PRETRAIN = Path(f'{ROOT_DIR_PATH}data/clip-marqofashionsiglip-marqoecom-top2kaggle')\n",
    "RESNET_PATH = Path(f'{ROOT_DIR_PATH}data/resnet-cossim/')\n",
    "KAGGLE_TOP5 = Path(f'{ROOT_DIR_PATH}data/top5-kaggle')\n",
    "BERTA_PATH = Path(f'{ROOT_DIR_PATH}data/berta-pretrained-cossims')\n",
    "RUBERT_TINY_OOF_PATH = Path(f'{ROOT_DIR_PATH}data/rubert-folds')\n",
    "RUBERT_TINY_PREDS_PATH = Path(f'{ROOT_DIR_PATH}data/rubert-test-preds')\n",
    "E5LARGE_OOF_PATH = Path(f'{ROOT_DIR_PATH}data/avito-e5-large-pretrain')\n",
    "E5LARGE_PREDS_PATH = Path(f'{ROOT_DIR_PATH}data/avito-e5-large-test')\n",
    "REV_RUBERT_TINY_OOF_PATH = Path(f'{ROOT_DIR_PATH}data/name_desc_bert_oof_rev') \n",
    "REV_RUBERT_TINY_PREDS_PATH = Path(f'{ROOT_DIR_PATH}data/name-desc-bert-preds-rev')\n",
    "USERBGE_COSSIMS_PATH = Path(f'{ROOT_DIR_PATH}data/userbge-cossims') \n",
    "RUBERT_BASE_TEST_PREDS_PATH = Path(f'{ROOT_DIR_PATH}data/rubert-fixed-test-preds') \n",
    "RUBERT_BASE_TEST_PREDS_REV_PATH = Path(f'{ROOT_DIR_PATH}data/rubert-fixed-test-preds-rev')\n",
    "FT_PREDS_PATH = Path(f'{ROOT_DIR_PATH}data/ft-preds2')\n",
    "RUBERT_BASE_OOF_PATH = Path(f'{ROOT_DIR_PATH}data/trained-rubert-base-preds')\n",
    "RUBERT_BASE_OOF_REV_PATH = Path(f'{ROOT_DIR_PATH}data/trained-rubert-base-preds-rev')\n",
    "ROUGE_PATH = Path(f'{ROOT_DIR_PATH}data/rouge-avito')\n",
    "\n",
    "USE_MEAN_BASE_AND_REV = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(MAIN_PATH)\n",
    "assert os.path.exists(ECOM_PRETRAIN)\n",
    "assert os.path.exists(RESNET_PATH)\n",
    "assert os.path.exists(KAGGLE_TOP5)\n",
    "assert os.path.exists(BERTA_PATH)\n",
    "assert os.path.exists(RUBERT_TINY_OOF_PATH)\n",
    "assert os.path.exists(RUBERT_TINY_PREDS_PATH)\n",
    "assert os.path.exists(E5LARGE_OOF_PATH)\n",
    "assert os.path.exists(E5LARGE_PREDS_PATH)\n",
    "assert os.path.exists(REV_RUBERT_TINY_OOF_PATH)\n",
    "assert os.path.exists(REV_RUBERT_TINY_PREDS_PATH)\n",
    "assert os.path.exists(USERBGE_COSSIMS_PATH)\n",
    "assert os.path.exists(RUBERT_BASE_TEST_PREDS_PATH)\n",
    "assert os.path.exists(RUBERT_BASE_TEST_PREDS_REV_PATH)\n",
    "assert os.path.exists(FT_PREDS_PATH)\n",
    "assert os.path.exists(RUBERT_BASE_OOF_PATH)\n",
    "assert os.path.exists(RUBERT_BASE_OOF_REV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    'is_same_location',\n",
    "    'is_same_region',\n",
    "    'category_level_1_match',\n",
    "    'category_level_2_match',\n",
    "    'category_level_3_match',\n",
    "    'category_level_4_match',\n",
    "    'category_level_3_fillness',\n",
    "    'category_level_4_fillness',\n",
    "    'n_images_fillness',\n",
    "    'unique_cat_1',\n",
    "    'unique_cat_2',\n",
    "    'unique_cat_3',\n",
    "    'unique_cat_4',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(MAIN_PATH / 'train_df.parquet')\n",
    "test = pd.read_parquet(MAIN_PATH / 'test_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = [\n",
    "    'category_level_1_1', 'category_level_1_2',\n",
    "    'category_level_2_1', 'category_level_2_2',\n",
    "    'category_level_3_1', 'category_level_3_2',\n",
    "    'category_level_4_1', 'category_level_4_2',\n",
    "]\n",
    "\n",
    "train[to_drop] = train[to_drop].fillna('none')\n",
    "\n",
    "train['unique_cat_1'] = train['category_level_1_1'] + '_' + train['category_level_1_2']\n",
    "train['unique_cat_2'] = train['category_level_2_1'] + '_' + train['category_level_2_2']\n",
    "train['unique_cat_3'] = train['category_level_3_1'] + '_' + train['category_level_3_2']\n",
    "train['unique_cat_4'] = train['category_level_4_1'] + '_' + train['category_level_4_2']\n",
    "\n",
    "test[to_drop] = test[to_drop].fillna('none')\n",
    "\n",
    "test['unique_cat_1'] = test['category_level_1_1'] + '_' + test['category_level_1_2']\n",
    "test['unique_cat_2'] = test['category_level_2_1'] + '_' + test['category_level_2_2']\n",
    "test['unique_cat_3'] = test['category_level_3_1'] + '_' + test['category_level_3_2']\n",
    "test['unique_cat_4'] = test['category_level_4_1'] + '_' + test['category_level_4_2']\n",
    "\n",
    "train.drop(columns=to_drop, axis=1, inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "test.drop(columns=to_drop, axis=1, inplace=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонки с inf: ['name_tanimoto', 'name_norm_tanimoto', 'name_en_tanimoto', 'name_mix_tanimoto', 'description_en_tanimoto', 'description_mix_tanimoto', 'name_tokens_w_digits_tanimoto', 'description_tokens_w_digits_tanimoto']\n"
     ]
    }
   ],
   "source": [
    "numerical_features = train.select_dtypes(\n",
    "    include=['float16', 'float32', 'float64', 'int8', 'int16', 'int32', 'int64']\n",
    ").columns.to_list()\n",
    "\n",
    "cols_with_inf = train[numerical_features].columns[np.isinf(train[numerical_features]).any()].tolist()\n",
    "\n",
    "print(\"Колонки с inf:\", cols_with_inf)\n",
    "\n",
    "train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "test.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cat_features] = train[cat_features].astype(str)\n",
    "test[cat_features] = test[cat_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.016258,
     "end_time": "2025-05-03T06:33:13.068082",
     "exception": false,
     "start_time": "2025-05-03T06:33:13.051824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                    gc.collect()\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                    gc.collect()\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                    gc.collect()\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "                    gc.collect()\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                    gc.collect()\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                    gc.collect()\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "                    gc.collect()\n",
    "        else:\n",
    "            if df[col].nunique() == 2:\n",
    "                df[col] = df[col].astype('bool')\n",
    "            gc.collect()\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 107.745228,
     "end_time": "2025-05-03T06:35:00.818992",
     "exception": false,
     "start_time": "2025-05-03T06:33:13.073764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 6546.15 MB\n",
      "Memory usage after optimization is: 1803.24 MB\n",
      "Decreased by 72.5%\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1741.41 MB\n",
      "Memory usage after optimization is: 472.55 MB\n",
      "Decreased by 72.9%\n"
     ]
    }
   ],
   "source": [
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "test = test.sort_values(by=['variantid_1', 'variantid_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userbge_cossims_train.shape=(125303, 3)\n",
      "userbge_cossims_train.shape=(250606, 3)\n",
      "userbge_cossims_train.shape=(375909, 3)\n",
      "userbge_cossims_train.shape=(501212, 3)\n",
      "userbge_cossims_train.shape=(626515, 3)\n",
      "userbge_cossims_train.shape=(751818, 3)\n",
      "userbge_cossims_train.shape=(877121, 3)\n",
      "userbge_cossims_train.shape=(1002424, 3)\n",
      "userbge_cossims_train.shape=(1127727, 3)\n",
      "userbge_cossims_train.shape=(1253030, 3)\n",
      "userbge_cossims_train.shape=(1378333, 3)\n",
      "userbge_cossims_train.shape=(1503636, 3)\n",
      "userbge_cossims_train.shape=(1628939, 3)\n",
      "userbge_cossims_train.shape=(1754242, 3)\n",
      "userbge_cossims_train.shape=(1879555, 3)\n",
      "userbge_cossims_test.shape=(125000, 3)\n",
      "userbge_cossims_test.shape=(250000, 3)\n",
      "userbge_cossims_test.shape=(375000, 3)\n",
      "userbge_cossims_test.shape=(500000, 3)\n"
     ]
    }
   ],
   "source": [
    "# --- IMG FEATURES ---\n",
    "\n",
    "# pretrain clip\n",
    "train_clip = pd.read_parquet(ECOM_PRETRAIN / 'cossim_final_embeddings_train_CLIP.parquet')\n",
    "test_clip = pd.read_parquet(ECOM_PRETRAIN / 'cossim_final_embeddings_test_CLIP.parquet')\n",
    "\n",
    "train_clip = train_clip.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "test_clip = test_clip.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "train['clip_cosine_sim'] = train_clip['cosine_sim']\n",
    "test['clip_cosine_sim'] = test_clip['cosine_sim']\n",
    "del train_clip, test_clip\n",
    "\n",
    "# pretrain fashion siglip\n",
    "train_fashionsiglip = pd.read_parquet(ECOM_PRETRAIN / 'cossim_final_embeddings_fashion_clip_train.parquet')\n",
    "test_fashionsiglip = pd.read_parquet(ECOM_PRETRAIN / 'cossim_final_embeddings_fashion_clip_test.parquet')\n",
    "\n",
    "train_fashionsiglip = train_fashionsiglip.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "test_fashionsiglip = test_fashionsiglip.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "train['fashionsiglip_cosine_sim'] = train_fashionsiglip['cosine_sim']\n",
    "test['fashionsiglip_cosine_sim'] = test_fashionsiglip['cosine_sim']\n",
    "del train_fashionsiglip, test_fashionsiglip\n",
    "\n",
    "# pretrain marqo ecom\n",
    "train_ecom = pd.read_parquet(ECOM_PRETRAIN / 'cossim_final_embeddings_ecomm_train.parquet')\n",
    "test_ecom = pd.read_parquet(ECOM_PRETRAIN / 'cossim_final_embeddings_ecomm_test.parquet')\n",
    "\n",
    "train_ecom = train_ecom.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "test_ecom = test_ecom.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "train['ecom_cosine_sim'] = train_ecom['cosine_sim']\n",
    "test['ecom_cosine_sim'] = test_ecom['cosine_sim']\n",
    "del train_ecom, test_ecom\n",
    "\n",
    "# kaggle top2 model, bugged\n",
    "# train_top2kaggle = pd.read_parquet(ECOM_PRETRAIN + 'cossim_final_top2_kaggle_train.parquet')\n",
    "# test_top2kaggle = pd.read_parquet(ECOM_PRETRAIN + 'cossim_final_top2_kaggle_test.parquet')\n",
    "\n",
    "# train_top2kaggle = train_top2kaggle.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "# test_top2kaggle = test_top2kaggle.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "# train['top2kaggle_cosine_sim'] = train_top2kaggle['cosine_sim']\n",
    "# test['top2kaggle_cosine_sim'] = test_top2kaggle['cosine_sim']\n",
    "# del train_top2kaggle, test_top2kaggle\n",
    "\n",
    "# kaggle top5 model\n",
    "train_top5kaggle = pd.read_parquet(KAGGLE_TOP5 / 'cossim_final_concat_train.parquet')\n",
    "test_top5kaggle = pd.read_parquet(KAGGLE_TOP5 / 'cossim_final_concat_test.parquet')\n",
    "\n",
    "train_top5kaggle = train_top5kaggle.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "test_top5kaggle = test_top5kaggle.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "train['top5kaggle_cosine_sim'] = train_top5kaggle['cosine_sim']\n",
    "test['top5kaggle_cosine_sim'] = test_top5kaggle['cosine_sim']\n",
    "del train_top5kaggle, test_top5kaggle\n",
    "\n",
    "# trained resnet\n",
    "train_resnet = pd.read_parquet(RESNET_PATH / 'train_resnet_cossim.parquet')\n",
    "test_resnet = pd.read_parquet(RESNET_PATH / 'test_resnet_cossim.parquet')\n",
    "\n",
    "train_resnet = train_resnet.sort_values(by=['variantid_1', 'variantid_2']).reset_index(drop=True)\n",
    "test_resnet = test_resnet.sort_values(by=['variantid_1', 'variantid_2']).reset_index(drop=True)\n",
    "train['resnet_cosine_sim'] = train_resnet['cossims_resnet']\n",
    "test['resnet_cosine_sim'] = test_resnet['cossims_resnet']\n",
    "del train_resnet, test_resnet\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# --- TEXT FEATURES ---\n",
    "\n",
    "# pretrain berta\n",
    "berta_cossims_train_part1 = pd.read_parquet(BERTA_PATH / 'berta_cossims_train_part1.parquet')\n",
    "berta_cossims_train_part2 = pd.read_parquet(BERTA_PATH / 'berta_cossims_train_part2.parquet')\n",
    "berta_cossims_train = pd.concat([berta_cossims_train_part1, berta_cossims_train_part2])\n",
    "berta_cossims_test = pd.read_parquet(BERTA_PATH / 'berta_cossims_test.parquet')\n",
    "\n",
    "berta_cossims_train = berta_cossims_train.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "berta_cossims_test = berta_cossims_test.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "train['berta_cossim'] = berta_cossims_train['berta_cossim']\n",
    "test['berta_cossim'] = berta_cossims_test['berta_cossim']\n",
    "\n",
    "del berta_cossims_train_part1, berta_cossims_train_part2, berta_cossims_train, berta_cossims_test\n",
    "gc.collect()\n",
    "\n",
    "# trained rubert (cherez zhopu rukamu obuchen)\n",
    "rubert_oof_fold0 = pd.read_parquet(RUBERT_TINY_OOF_PATH / 'name_desc_bert_fold0.parquet')\n",
    "rubert_oof_fold1 = pd.read_parquet(RUBERT_TINY_OOF_PATH / 'name_desc_bert_fold1.parquet')\n",
    "rubert_oof_fold2 = pd.read_parquet(RUBERT_TINY_OOF_PATH / 'name_desc_bert_fold2.parquet')\n",
    "rubert_oof_fold3 = pd.read_parquet(RUBERT_TINY_OOF_PATH / 'name_desc_bert_fold3.parquet')\n",
    "rubert_oof_fold4 = pd.read_parquet(RUBERT_TINY_OOF_PATH / 'name_desc_bert_fold4.parquet')\n",
    "\n",
    "rubert_test_pred_fold0 = pd.read_parquet(RUBERT_TINY_PREDS_PATH / 'name_desc_rubert_tiny_turbo_2048_wce_0.parquet')\n",
    "rubert_test_pred_fold1 = pd.read_parquet(RUBERT_TINY_PREDS_PATH / 'name_desc_rubert_tiny_turbo_2048_wce_1.parquet')\n",
    "rubert_test_pred_fold2 = pd.read_parquet(RUBERT_TINY_PREDS_PATH / 'name_desc_rubert_tiny_turbo_2048_wce_2.parquet')\n",
    "rubert_test_pred_fold3 = pd.read_parquet(RUBERT_TINY_PREDS_PATH / 'name_desc_rubert_tiny_turbo_2048_wce_3.parquet')\n",
    "rubert_test_pred_fold4 = pd.read_parquet(RUBERT_TINY_PREDS_PATH / 'name_desc_rubert_tiny_turbo_2048_wce_4.parquet')\n",
    "\n",
    "rubert_oof_fold0.rename(columns={'name_desc_bert_oof1': 'name_desc_rubert_tiny_turbo_2048_wce'}, inplace=True)\n",
    "rubert_oof_fold1.rename(columns={'name_desc_bert_oof4': 'name_desc_rubert_tiny_turbo_2048_wce'}, inplace=True)\n",
    "rubert_oof_fold2.rename(columns={'name_desc_bert_oof4': 'name_desc_rubert_tiny_turbo_2048_wce'}, inplace=True)\n",
    "rubert_oof_fold3.rename(columns={'name_desc_bert_oof4': 'name_desc_rubert_tiny_turbo_2048_wce'}, inplace=True)\n",
    "rubert_oof_fold4.rename(columns={'name_desc_bert_oof4': 'name_desc_rubert_tiny_turbo_2048_wce'}, inplace=True)\n",
    "\n",
    "rubert_oof_fold0 = rubert_oof_fold0.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "rubert_oof_fold1 = rubert_oof_fold1.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "rubert_oof_fold2 = rubert_oof_fold2.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "rubert_oof_fold3 = rubert_oof_fold3.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "rubert_oof_fold4 = rubert_oof_fold4.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "\n",
    "rubert_oof = rubert_oof_fold0['name_desc_rubert_tiny_turbo_2048_wce'] + \\\n",
    "    rubert_oof_fold1['name_desc_rubert_tiny_turbo_2048_wce'] + \\\n",
    "    rubert_oof_fold2['name_desc_rubert_tiny_turbo_2048_wce'] + \\\n",
    "    rubert_oof_fold3['name_desc_rubert_tiny_turbo_2048_wce'] + \\\n",
    "    rubert_oof_fold4['name_desc_rubert_tiny_turbo_2048_wce']\n",
    "\n",
    "rubert_test_pred_fold0 = rubert_test_pred_fold0.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "rubert_test_pred_fold1 = rubert_test_pred_fold1.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "rubert_test_pred_fold2 = rubert_test_pred_fold2.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "rubert_test_pred_fold3 = rubert_test_pred_fold3.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "rubert_test_pred_fold4 = rubert_test_pred_fold4.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "\n",
    "rubert_preds = (\n",
    "    rubert_test_pred_fold0['name_desc_rubert_tiny_turbo_2048_wce_0'] + \n",
    "    rubert_test_pred_fold1['name_desc_rubert_tiny_turbo_2048_wce_1'] + \n",
    "    rubert_test_pred_fold2['name_desc_rubert_tiny_turbo_2048_wce_2'] + \n",
    "    rubert_test_pred_fold3['name_desc_rubert_tiny_turbo_2048_wce_3'] + \n",
    "    rubert_test_pred_fold4['name_desc_rubert_tiny_turbo_2048_wce_4']\n",
    "    ) / 5\n",
    "\n",
    "train['name_desc_rubert_tiny_turbo_2048_wce'] = rubert_oof\n",
    "test['name_desc_rubert_tiny_turbo_2048_wce'] = rubert_preds\n",
    "\n",
    "del rubert_oof_fold0, rubert_oof_fold1, rubert_oof_fold2, rubert_oof_fold3, rubert_oof_fold4\n",
    "del rubert_oof\n",
    "del rubert_test_pred_fold0, rubert_test_pred_fold1, rubert_test_pred_fold2, rubert_test_pred_fold3, rubert_test_pred_fold4\n",
    "del rubert_preds\n",
    "gc.collect()\n",
    "\n",
    "# pretrain e5large\n",
    "e5large_cossims_train_part1 = pd.read_parquet(E5LARGE_OOF_PATH / 'e5large_cossims_fold0.parquet')\n",
    "e5large_cossims_train_part2 = pd.read_parquet(E5LARGE_OOF_PATH / 'e5large_cossims_fold1.parquet')\n",
    "e5large_cossims_train_part3 = pd.read_parquet(E5LARGE_OOF_PATH / 'e5large_cossims_fold2.parquet')\n",
    "e5large_cossims_train_part4 = pd.read_parquet(E5LARGE_OOF_PATH / 'e5large_cossims_fold3.parquet')\n",
    "e5large_cossims_train_part5 = pd.read_parquet(E5LARGE_OOF_PATH / 'e5large_cossims_fold4.parquet')\n",
    "\n",
    "e5large_cossims_train = pd.concat([\n",
    "    e5large_cossims_train_part1,\n",
    "    e5large_cossims_train_part2,\n",
    "    e5large_cossims_train_part3,\n",
    "    e5large_cossims_train_part4,\n",
    "    e5large_cossims_train_part5\n",
    "])\n",
    "e5large_cossims_train = e5large_cossims_train.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "\n",
    "del e5large_cossims_train_part1, e5large_cossims_train_part2, e5large_cossims_train_part3, e5large_cossims_train_part4, e5large_cossims_train_part5\n",
    "gc.collect()\n",
    "\n",
    "e5large_cossims_test_part1 = pd.read_parquet(E5LARGE_PREDS_PATH / 'e5large_cossims_part1.parquet')\n",
    "e5large_cossims_test_part2 = pd.read_parquet(E5LARGE_PREDS_PATH / 'e5large_cossims_part2.parquet')\n",
    "\n",
    "e5large_cossims_test = pd.concat([\n",
    "    e5large_cossims_test_part1,\n",
    "    e5large_cossims_test_part2,\n",
    "])\n",
    "e5large_cossims_test = e5large_cossims_test.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "\n",
    "del e5large_cossims_test_part1, e5large_cossims_test_part2\n",
    "gc.collect()\n",
    "\n",
    "train['e5large_cossim'] = e5large_cossims_train['e5large_cossim']\n",
    "test['e5large_cossim'] = e5large_cossims_test['e5large_cossim']\n",
    "\n",
    "del e5large_cossims_train, e5large_cossims_test\n",
    "gc.collect()\n",
    "\n",
    "# rev trained rubert (cherez zhopu rukamu obuchen)\n",
    "rubert_oof_rev = pd.read_parquet(REV_RUBERT_TINY_OOF_PATH / 'name_desc_bert_oof_rev.parquet')\n",
    "rubert_preds_rev = pd.read_parquet(REV_RUBERT_TINY_PREDS_PATH / 'name_desc_bert_preds_rev.parquet')\n",
    "\n",
    "rubert_oof_rev = rubert_oof_rev.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "rubert_preds_rev = rubert_preds_rev.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "train['name_desc_rubert_tiny_turbo_2048_wce_rev'] = rubert_oof_rev['name_desc_bert_oof_rev']\n",
    "test['name_desc_rubert_tiny_turbo_2048_wce_rev'] = rubert_preds_rev['name_desc_bert_preds_rev']\n",
    "del rubert_oof_rev, rubert_preds_rev\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# rubert tta\n",
    "if USE_MEAN_BASE_AND_REV:\n",
    "    train['name_desc_rubert_tiny_turbo_2048_wce_tta'] = (train['name_desc_rubert_tiny_turbo_2048_wce'] / train['name_desc_rubert_tiny_turbo_2048_wce_rev']) / 2\n",
    "    test['name_desc_rubert_tiny_turbo_2048_wce_tta'] = (test['name_desc_rubert_tiny_turbo_2048_wce'] / test['name_desc_rubert_tiny_turbo_2048_wce_rev']) / 2\n",
    "    del train['name_desc_rubert_tiny_turbo_2048_wce'], train['name_desc_rubert_tiny_turbo_2048_wce_rev']\n",
    "    del test['name_desc_rubert_tiny_turbo_2048_wce'], test['name_desc_rubert_tiny_turbo_2048_wce_rev']\n",
    "    gc.collect()\n",
    "\n",
    "# pretrain userbge\n",
    "userbge_cossims_train = pd.DataFrame()\n",
    "userbge_cossims_test = pd.DataFrame()\n",
    "\n",
    "for i in range(1, 16):\n",
    "    curr_df = pd.read_parquet(USERBGE_COSSIMS_PATH / f'userbge_cossims_train_part{i}.parquet')\n",
    "    userbge_cossims_train = pd.concat([userbge_cossims_train, curr_df])\n",
    "    print(f'{userbge_cossims_train.shape=}')\n",
    "userbge_cossims_train = userbge_cossims_train.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "\n",
    "for i in range(1, 5):\n",
    "    curr_df = pd.read_parquet(USERBGE_COSSIMS_PATH / f'userbge_cossims_test_part{i}.parquet')\n",
    "    userbge_cossims_test = pd.concat([userbge_cossims_test, curr_df])\n",
    "    print(f'{userbge_cossims_test.shape=}')\n",
    "userbge_cossims_test = userbge_cossims_test.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "\n",
    "del curr_df\n",
    "gc.collect()\n",
    "\n",
    "train['userbge_cossim'] = userbge_cossims_train['userbge_cossim']\n",
    "test['userbge_cossim'] = userbge_cossims_test['userbge_cossim']\n",
    "\n",
    "del userbge_cossims_train, userbge_cossims_test\n",
    "gc.collect()\n",
    "\n",
    "# --- тут именно до сэмпла! ---\n",
    "\n",
    "# trained rubert-base test preds\n",
    "rubert_base_pred = pd.read_csv(\n",
    "    RUBERT_BASE_TEST_PREDS_PATH / 'rubert_ZAEBAL_SUKA.csv'\n",
    ").rename(columns={'base_id': 'variantid_1', 'cand_id': 'variantid_2'})\n",
    "rubert_base_pred = rubert_base_pred.sort_values(by=['variantid_1', 'variantid_2']).reset_index(drop=True)\n",
    "test['rubert_base_trained'] = rubert_base_pred['probability']\n",
    "\n",
    "rubert_base_pred_rev = pd.read_csv(\n",
    "    RUBERT_BASE_TEST_PREDS_REV_PATH / 'rubert_ZAEBAL_SUKA_REV.csv'\n",
    ").rename(columns={'base_id': 'variantid_1', 'cand_id': 'variantid_2'})\n",
    "rubert_base_pred_rev = rubert_base_pred_rev.sort_values(by=['variantid_1', 'variantid_2']).reset_index(drop=True)\n",
    "test['rubert_base_trained_rev'] = rubert_base_pred_rev['probability']\n",
    "\n",
    "del rubert_base_pred, rubert_base_pred_rev\n",
    "gc.collect()\n",
    "\n",
    "# rubert base test tta\n",
    "if USE_MEAN_BASE_AND_REV:\n",
    "    test['rubert_base_trained_tta'] = (test['rubert_base_trained'] + test['rubert_base_trained_rev']) / 2\n",
    "    del test['rubert_base_trained'],  test['rubert_base_trained_rev']\n",
    "    gc.collect()\n",
    "\n",
    "# --- sample!!! ---\n",
    "train = train.sample(len(train), random_state=42)\n",
    "\n",
    "# trained ft (именно после сэмпла! тут уже все карты в нужном порядке разложены)\n",
    "fasttext_train = joblib.load(FT_PREDS_PATH / 'oof_preds.pkl')\n",
    "fasttext_test = joblib.load(FT_PREDS_PATH / 'test_preds.pkl')\n",
    "fasttext_train_rev = joblib.load(FT_PREDS_PATH / 'oof_preds_rev.pkl')\n",
    "fasttext_test_rev = joblib.load(FT_PREDS_PATH / 'test_preds_rev.pkl')\n",
    "\n",
    "train['fasttext'] = fasttext_train\n",
    "test['fasttext'] = fasttext_test\n",
    "train['fasttext_rev'] = fasttext_train_rev\n",
    "test['fasttext_rev'] = fasttext_test_rev\n",
    "\n",
    "del fasttext_train, fasttext_test, fasttext_train_rev, fasttext_test_rev\n",
    "gc.collect()\n",
    "\n",
    "# fasttext tta\n",
    "if USE_MEAN_BASE_AND_REV:\n",
    "    train['fasttext_tta'] = (train['fasttext'] + train['fasttext_rev']) / 2\n",
    "    test['fasttext_tta'] = (test['fasttext'] + test['fasttext_rev']) / 2\n",
    "    del train['fasttext'], train['fasttext_rev']\n",
    "    del test['fasttext'], test['fasttext_rev']\n",
    "    gc.collect()\n",
    "\n",
    "# trained rubert-base train (именно после сэмпла! тут уже все карты в нужном порядке разложены)\n",
    "rubert_base_oof = joblib.load(RUBERT_BASE_OOF_PATH / 'oof_preds_rubert_base.joblib')\n",
    "train['rubert_base_trained'] = rubert_base_oof\n",
    "\n",
    "rubert_base_oof_rev = joblib.load(RUBERT_BASE_OOF_REV_PATH / 'oof_preds_rubert_base_rev.joblib')\n",
    "train['rubert_base_trained_rev'] = rubert_base_oof_rev\n",
    "\n",
    "del rubert_base_oof, rubert_base_oof_rev\n",
    "gc.collect()\n",
    "\n",
    "# rubert train test tta\n",
    "if USE_MEAN_BASE_AND_REV:\n",
    "    train['rubert_base_trained_tta'] = (train['rubert_base_trained'] + train['rubert_base_trained_rev']) / 2\n",
    "    del train['rubert_base_trained'],  train['rubert_base_trained_rev']\n",
    "    gc.collect()\n",
    "\n",
    "# add rouge features (w/ tta)\n",
    "\n",
    "train_rouge = pd.read_csv(ROUGE_PATH / 'train_rouge.csv')\n",
    "test_rouge = pd.read_csv(ROUGE_PATH / 'test_rouge.csv')\n",
    "\n",
    "train_rouge = train_rouge.sort_values(by=['variantid_1', 'variantid_2']).reset_index(drop=True)\n",
    "test_rouge = test_rouge.sort_values(by=['variantid_1', 'variantid_2']).reset_index(drop=True)\n",
    "\n",
    "train['rouge_1'] = train_rouge['rouge_1']\n",
    "train['rouge_2'] = train_rouge['rouge_2']\n",
    "train['rouge_3'] = train_rouge['rouge_3']\n",
    "train['rouge_4'] = train_rouge['rouge_4']\n",
    "train['rouge_s4'] = train_rouge['rouge_s4']\n",
    "train['rouge_su4'] = train_rouge['rouge_su4']\n",
    "\n",
    "test['rouge_1'] = test_rouge['rouge_1']\n",
    "test['rouge_2'] = test_rouge['rouge_2']\n",
    "test['rouge_3'] = test_rouge['rouge_3']\n",
    "test['rouge_4'] = test_rouge['rouge_4']\n",
    "test['rouge_s4'] = test_rouge['rouge_s4']\n",
    "test['rouge_su4'] = test_rouge['rouge_su4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['variantid_1', 'variantid_2', 'base_title_image', 'cand_title_image'], axis=1, inplace=True)\n",
    "test.drop(columns=['variantid_1', 'variantid_2', 'base_title_image', 'cand_title_image'], axis=1, inplace=True)\n",
    "train.drop(columns=['action_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train.columns if col not in ['group_id', 'is_double']]\n",
    "target = 'is_double'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc(y_true, y_pred):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    return auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prauc_metric(y_true, y_pred, sample_weight, **kwargs):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    return auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 6\n",
    "N_FOLDS = 10\n",
    "RANDOM_STATE = 42\n",
    "TIMEOUT = 4 * 24 * 3600\n",
    "TARGET_NAME = 'is_double'\n",
    "GROUP = 'group_id'\n",
    "\n",
    "MEMORY_LIMIT = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task('binary', metric=prauc_metric, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {\n",
    "    'target': TARGET_NAME,\n",
    "    'drop': [GROUP],\n",
    "    'category': cat_features,\n",
    "    'group': [GROUP]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularUtilizedAutoML(\n",
    "    task=task, \n",
    "    timeout=TIMEOUT,\n",
    "    cpu_limit=N_THREADS,\n",
    "    memory_limit=MEMORY_LIMIT,\n",
    "    tuning_params={'max_tuning_time': 3600 * 8}, # 8ч на тюн каждой залупы\n",
    "    reader_params = {\n",
    "        'n_jobs': N_THREADS, \n",
    "        'cv': N_FOLDS, \n",
    "        'random_state': RANDOM_STATE\n",
    "    },\n",
    "    selection_params={'mode': 0},\n",
    "    general_params = {\n",
    "        'use_algos': [[\n",
    "            'lgb', 'lgb_tuned', # таргет энкодинг не надо! все и так ок\n",
    "            'cb', 'cb_tuned', \n",
    "            'xgb', 'xgb_tuned'\n",
    "    ]]\n",
    "    },\n",
    "    gpu_ids='0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "oof_pred = automl.fit_predict(train, roles=roles, verbose=3, log_file='automl_train.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score: 0.6441786282375546\n"
     ]
    }
   ],
   "source": [
    "print(f'OOF score: {pr_auc(train[TARGET_NAME].values, oof_pred.data[:, 0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = automl.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_pred.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(test_pred, 'test_pred.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction for new objects = \n",
      "\t0.35189 * 1 averaged models with config = \"C:\\Program Files\\Python311\\Lib\\site-packages\\lightautoml\\automl\\presets\\tabular_configs\\conf_0_sel_type_0.yml\" and different CV random_states. Their structures: \n",
      "\n",
      "\t    Model #0.\n",
      "\t\t================================================================================\n",
      "\t\tFinal prediction for new objects (level 0) = \n",
      "\t\t\t 0.06644 * (10 averaged models Lvl_0_Pipe_0_Mod_0_LightGBM) +\n",
      "\t\t\t 0.26423 * (10 averaged models Lvl_0_Pipe_0_Mod_1_Tuned_LightGBM) +\n",
      "\t\t\t 0.29731 * (10 averaged models Lvl_0_Pipe_0_Mod_3_Tuned_CatBoost) +\n",
      "\t\t\t 0.06856 * (10 averaged models Lvl_0_Pipe_0_Mod_4_XGBoost) +\n",
      "\t\t\t 0.30345 * (10 averaged models Lvl_0_Pipe_0_Mod_5_Tuned_XGBoost) \n",
      "\t\t================================================================================\n",
      "\n",
      "\n",
      "\t+ 0.22403 * 1 averaged models with config = \"C:\\Program Files\\Python311\\Lib\\site-packages\\lightautoml\\automl\\presets\\tabular_configs\\conf_1_sel_type_1.yml\" and different CV random_states. Their structures: \n",
      "\n",
      "\t    Model #0.\n",
      "\t\t================================================================================\n",
      "\t\tFinal prediction for new objects (level 0) = \n",
      "\t\t\t 0.06293 * (10 averaged models Lvl_0_Pipe_0_Mod_0_LightGBM) +\n",
      "\t\t\t 0.20055 * (10 averaged models Lvl_0_Pipe_0_Mod_1_Tuned_LightGBM) +\n",
      "\t\t\t 0.24964 * (10 averaged models Lvl_0_Pipe_0_Mod_3_Tuned_CatBoost) +\n",
      "\t\t\t 0.09061 * (10 averaged models Lvl_0_Pipe_0_Mod_4_XGBoost) +\n",
      "\t\t\t 0.39627 * (10 averaged models Lvl_0_Pipe_0_Mod_5_Tuned_XGBoost) \n",
      "\t\t================================================================================\n",
      "\n",
      "\n",
      "\t+ 0.42408 * 1 averaged models with config = \"C:\\Program Files\\Python311\\Lib\\site-packages\\lightautoml\\automl\\presets\\tabular_configs\\conf_2_select_mode_1_no_typ.yml\" and different CV random_states. Their structures: \n",
      "\n",
      "\t    Model #0.\n",
      "\t\t================================================================================\n",
      "\t\tFinal prediction for new objects (level 0) = \n",
      "\t\t\t 0.11779 * (10 averaged models Lvl_0_Pipe_0_Mod_1_Tuned_LightGBM) +\n",
      "\t\t\t 0.13135 * (10 averaged models Lvl_0_Pipe_0_Mod_3_Tuned_CatBoost) +\n",
      "\t\t\t 0.09840 * (10 averaged models Lvl_0_Pipe_0_Mod_4_XGBoost) +\n",
      "\t\t\t 0.65246 * (10 averaged models Lvl_0_Pipe_0_Mod_5_Tuned_XGBoost) \n",
      "\t\t================================================================================\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(automl.create_model_str_desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['automl_27052025_0.6441786282375546.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(automl, 'automl_27052025_0.6441786282375546.joblib')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7125408,
     "sourceId": 11380218,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7220315,
     "sourceId": 11513967,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7256540,
     "sourceId": 11574115,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7210517,
     "sourceId": 11590590,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7267982,
     "sourceId": 11590633,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7284947,
     "sourceId": 11613735,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7285417,
     "sourceId": 11614326,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7287539,
     "sourceId": 11617055,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7304054,
     "sourceId": 11640334,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7315801,
     "sourceId": 11657806,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7324305,
     "sourceId": 11670832,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7328955,
     "sourceId": 11677210,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7336890,
     "sourceId": 11689474,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7337448,
     "sourceId": 11690292,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7347238,
     "sourceId": 11713654,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 235374010,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 329243,
     "modelInstanceId": 308841,
     "sourceId": 373294,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 329243,
     "modelInstanceId": 308841,
     "sourceId": 373297,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 329243,
     "modelInstanceId": 308841,
     "sourceId": 373299,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 329243,
     "modelInstanceId": 308841,
     "sourceId": 373302,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 330045,
     "modelInstanceId": 309673,
     "sourceId": 374580,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 330045,
     "modelInstanceId": 309673,
     "sourceId": 374581,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 330045,
     "modelInstanceId": 309673,
     "sourceId": 374625,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 330045,
     "modelInstanceId": 309673,
     "sourceId": 374629,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 330045,
     "modelInstanceId": 309673,
     "sourceId": 374669,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 330498,
     "modelInstanceId": 310127,
     "sourceId": 375189,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 330501,
     "modelInstanceId": 310131,
     "sourceId": 375194,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 330501,
     "modelInstanceId": 310131,
     "sourceId": 375195,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 330498,
     "modelInstanceId": 310127,
     "sourceId": 375876,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 330498,
     "modelInstanceId": 310127,
     "sourceId": 375877,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 331611,
     "modelInstanceId": 311257,
     "sourceId": 376792,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 331611,
     "modelInstanceId": 311257,
     "sourceId": 376819,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5295.446888,
   "end_time": "2025-05-03T08:00:44.602420",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-03T06:32:29.155532",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
