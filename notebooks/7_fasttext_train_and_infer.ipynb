{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a94994a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:14:52.230977Z",
     "iopub.status.busy": "2025-05-02T18:14:52.230641Z",
     "iopub.status.idle": "2025-05-02T18:15:05.334541Z",
     "shell.execute_reply": "2025-05-02T18:15:05.333513Z"
    },
    "papermill": {
     "duration": 13.110973,
     "end_time": "2025-05-02T18:15:05.336386",
     "exception": false,
     "start_time": "2025-05-02T18:14:52.225413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting razdel\r\n",
      "  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\r\n",
      "Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\r\n",
      "Installing collected packages: razdel\r\n",
      "Successfully installed razdel-0.5.0\r\n",
      "Collecting pymorphy3\r\n",
      "  Downloading pymorphy3-2.0.3-py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Collecting dawg2-python>=0.8.0 (from pymorphy3)\r\n",
      "  Downloading dawg2_python-0.9.0-py3-none-any.whl.metadata (7.5 kB)\r\n",
      "Collecting pymorphy3-dicts-ru (from pymorphy3)\r\n",
      "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl.metadata (2.0 kB)\r\n",
      "Downloading pymorphy3-2.0.3-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading dawg2_python-0.9.0-py3-none-any.whl (9.3 kB)\r\n",
      "Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pymorphy3-dicts-ru, dawg2-python, pymorphy3\r\n",
      "Successfully installed dawg2-python-0.9.0 pymorphy3-2.0.3 pymorphy3-dicts-ru-2.4.417150.4580142\r\n",
      "Collecting pymorphy2-dicts-ru\r\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pymorphy2-dicts-ru\r\n",
      "Successfully installed pymorphy2-dicts-ru-2.4.417127.4579844\r\n"
     ]
    }
   ],
   "source": [
    "!pip install razdel\n",
    "!pip install pymorphy3\n",
    "!pip install -U pymorphy2-dicts-ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74eabf6d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:05.347521Z",
     "iopub.status.busy": "2025-05-02T18:15:05.347188Z",
     "iopub.status.idle": "2025-05-02T18:15:09.692690Z",
     "shell.execute_reply": "2025-05-02T18:15:09.691912Z"
    },
    "papermill": {
     "duration": 4.352812,
     "end_time": "2025-05-02T18:15:09.694338",
     "exception": false,
     "start_time": "2025-05-02T18:15:05.341526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import tarfile\n",
    "from functools import cache\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import pymorphy3 as pm\n",
    "from nltk.corpus import stopwords\n",
    "from razdel import tokenize\n",
    "from string import punctuation\n",
    "\n",
    "import fasttext\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7a1dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:09.704830Z",
     "iopub.status.busy": "2025-05-02T18:15:09.704406Z",
     "iopub.status.idle": "2025-05-02T18:15:09.708908Z",
     "shell.execute_reply": "2025-05-02T18:15:09.708267Z"
    },
    "papermill": {
     "duration": 0.011178,
     "end_time": "2025-05-02T18:15:09.710257",
     "exception": false,
     "start_time": "2025-05-02T18:15:09.699079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51b8794",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:09.720394Z",
     "iopub.status.busy": "2025-05-02T18:15:09.720064Z",
     "iopub.status.idle": "2025-05-02T18:15:09.723780Z",
     "shell.execute_reply": "2025-05-02T18:15:09.723148Z"
    },
    "papermill": {
     "duration": 0.010164,
     "end_time": "2025-05-02T18:15:09.725001",
     "exception": false,
     "start_time": "2025-05-02T18:15:09.714837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1st stage\n",
    "\n",
    "# PREPROCESS_DATA = True\n",
    "# DO_SWAP = False\n",
    "# TRAIN_MODEL = False\n",
    "\n",
    "# GET_REV_OOFS = False\n",
    "\n",
    "# DO_INFER = False\n",
    "# DO_INFER_REV = False\n",
    "\n",
    "# DESC_N = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b8e5979",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:09.735574Z",
     "iopub.status.busy": "2025-05-02T18:15:09.734776Z",
     "iopub.status.idle": "2025-05-02T18:15:09.738651Z",
     "shell.execute_reply": "2025-05-02T18:15:09.737972Z"
    },
    "papermill": {
     "duration": 0.010337,
     "end_time": "2025-05-02T18:15:09.739821",
     "exception": false,
     "start_time": "2025-05-02T18:15:09.729484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2nd stage\n",
    "\n",
    "# PREPROCESS_DATA = True\n",
    "# DO_SWAP = True\n",
    "# TRAIN_MODEL = False\n",
    "\n",
    "# GET_REV_OOFS = False\n",
    "\n",
    "# DO_INFER = False\n",
    "# DO_INFER_REV = False\n",
    "\n",
    "# DESC_N = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6065ecb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:09.749835Z",
     "iopub.status.busy": "2025-05-02T18:15:09.749552Z",
     "iopub.status.idle": "2025-05-02T18:15:09.753311Z",
     "shell.execute_reply": "2025-05-02T18:15:09.752578Z"
    },
    "papermill": {
     "duration": 0.010157,
     "end_time": "2025-05-02T18:15:09.754547",
     "exception": false,
     "start_time": "2025-05-02T18:15:09.744390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3rd stage\n",
    "\n",
    "# PREPROCESS_DATA = False\n",
    "# DO_SWAP = False\n",
    "# TRAIN_MODEL = True # use default data as train data\n",
    "\n",
    "# GET_REV_OOFS = False\n",
    "\n",
    "# DO_INFER = False\n",
    "# DO_INFER_REV = False\n",
    "\n",
    "# DESC_N = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "602907be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:09.765196Z",
     "iopub.status.busy": "2025-05-02T18:15:09.764840Z",
     "iopub.status.idle": "2025-05-02T18:15:09.768808Z",
     "shell.execute_reply": "2025-05-02T18:15:09.767942Z"
    },
    "papermill": {
     "duration": 0.010756,
     "end_time": "2025-05-02T18:15:09.770166",
     "exception": false,
     "start_time": "2025-05-02T18:15:09.759410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4th stage\n",
    "\n",
    "# PREPROCESS_DATA = False\n",
    "# DO_SWAP = False\n",
    "# TRAIN_MODEL = True # use reversed data as train data\n",
    "\n",
    "# GET_REV_OOFS = False\n",
    "\n",
    "# DO_INFER = False\n",
    "# DO_INFER_REV = False\n",
    "\n",
    "# DESC_N = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9422b3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:09.780587Z",
     "iopub.status.busy": "2025-05-02T18:15:09.780285Z",
     "iopub.status.idle": "2025-05-02T18:15:09.784975Z",
     "shell.execute_reply": "2025-05-02T18:15:09.784336Z"
    },
    "papermill": {
     "duration": 0.011541,
     "end_time": "2025-05-02T18:15:09.786364",
     "exception": false,
     "start_time": "2025-05-02T18:15:09.774823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5th stage\n",
    "\n",
    "PREPROCESS_DATA = False\n",
    "DO_SWAP = False\n",
    "TRAIN_MODEL = False\n",
    "\n",
    "GET_REV_OOFS = False\n",
    "\n",
    "DO_INFER = True\n",
    "DO_INFER_REV = True\n",
    "\n",
    "DESC_N = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c5e47a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:09.796649Z",
     "iopub.status.busy": "2025-05-02T18:15:09.796338Z",
     "iopub.status.idle": "2025-05-02T18:15:09.859431Z",
     "shell.execute_reply": "2025-05-02T18:15:09.858457Z"
    },
    "papermill": {
     "duration": 0.070032,
     "end_time": "2025-05-02T18:15:09.861113",
     "exception": false,
     "start_time": "2025-05-02T18:15:09.791081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('russian')\n",
    "punkt = [p for p in punctuation] + [\"`\", \"``\" , \"''\", \"'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e63dc23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:09.872329Z",
     "iopub.status.busy": "2025-05-02T18:15:09.871676Z",
     "iopub.status.idle": "2025-05-02T18:15:09.980763Z",
     "shell.execute_reply": "2025-05-02T18:15:09.979858Z"
    },
    "papermill": {
     "duration": 0.116233,
     "end_time": "2025-05-02T18:15:09.982423",
     "exception": false,
     "start_time": "2025-05-02T18:15:09.866190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "morph = pm.MorphAnalyzer(lang='ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eee03dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:09.993548Z",
     "iopub.status.busy": "2025-05-02T18:15:09.993205Z",
     "iopub.status.idle": "2025-05-02T18:15:10.003064Z",
     "shell.execute_reply": "2025-05-02T18:15:10.002130Z"
    },
    "papermill": {
     "duration": 0.017294,
     "end_time": "2025-05-02T18:15:10.004705",
     "exception": false,
     "start_time": "2025-05-02T18:15:09.987411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @cache\n",
    "def tokenize_(sent):\n",
    "    sent = tokenize(sent)\n",
    "    return [word.text for word in sent if word.text not in stop and word.text not in punkt]\n",
    "\n",
    "@cache\n",
    "def normalize(word):\n",
    "    try:\n",
    "        return morph.normal_forms(word)[0]\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "def lemmatize(sent):\n",
    "    return ' '.join([normalize(word) for word in sent])\n",
    "\n",
    "# @cache\n",
    "def preprocess_sent(sent):\n",
    "    return lemmatize(tokenize_(sent))\n",
    "\n",
    "def prepare(row):\n",
    "    ret = ' '.join([\n",
    "        ' _'.join([''] + preprocess_sent(row['name_1']).split()),\n",
    "        '~'.join([''] + row['category_level_1_1'].split()) if row['category_level_1_1'] else '',\n",
    "        '!'.join([''] + row['category_level_2_1'].split()) if row['category_level_2_1'] else '',\n",
    "        '@'.join([''] + row['category_level_3_1'].split()) if row['category_level_3_1'] else '',\n",
    "        '#'.join([''] + row['category_level_4_1'].split()) if row['category_level_4_1'] else '',\n",
    "        preprocess_sent(row['description_1'].replace('\\n', ' ')),\n",
    "        ' _'.join([''] + preprocess_sent(row['name_2']).upper().split()),\n",
    "        '~'.join([''] + row['category_level_1_2'].upper().split()) if row['category_level_1_2'] else '',\n",
    "        '!'.join([''] + row['category_level_2_2'].upper().split()) if row['category_level_2_2'] else '',\n",
    "        '@'.join([''] + row['category_level_3_2'].upper().split()) if row['category_level_3_2'] else '',\n",
    "        '#'.join([''] + row['category_level_4_2'].upper().split()) if row['category_level_4_2'] else '',\n",
    "        preprocess_sent(row['description_2'].replace('\\n', ' ')).upper(),\n",
    "    ])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "673a17ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:10.015885Z",
     "iopub.status.busy": "2025-05-02T18:15:10.015353Z",
     "iopub.status.idle": "2025-05-02T18:15:10.020446Z",
     "shell.execute_reply": "2025-05-02T18:15:10.019600Z"
    },
    "papermill": {
     "duration": 0.012086,
     "end_time": "2025-05-02T18:15:10.021747",
     "exception": false,
     "start_time": "2025-05-02T18:15:10.009661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_html_tags_and_emoji(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "    clean = re.compile('<.*?>')\n",
    "    text = re.sub(clean, '', text)\n",
    "    text = text.replace('\\n', ' ')\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd2ccba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:10.032547Z",
     "iopub.status.busy": "2025-05-02T18:15:10.032236Z",
     "iopub.status.idle": "2025-05-02T18:15:10.039598Z",
     "shell.execute_reply": "2025-05-02T18:15:10.038842Z"
    },
    "papermill": {
     "duration": 0.014306,
     "end_time": "2025-05-02T18:15:10.040812",
     "exception": false,
     "start_time": "2025-05-02T18:15:10.026506",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    train_df1 = pd.read_parquet('../data/preprocessed/train_texts.parquet')\n",
    "\n",
    "    if DO_SWAP:\n",
    "        cols_to_swap = [\n",
    "            # ('variantid_1', 'variantid_2'),\n",
    "            ('name_1', 'name_2'),\n",
    "            ('description_1', 'description_2'),\n",
    "            ('category_level_1_1', 'category_level_1_2'),\n",
    "            ('category_level_2_1', 'category_level_2_2'),\n",
    "            ('category_level_3_1', 'category_level_3_2'),\n",
    "            ('category_level_4_1', 'category_level_4_2'),\n",
    "            ('characteristic_attributes_mapping_1', 'characteristic_attributes_mapping_2')\n",
    "        ]\n",
    "    \n",
    "        rename_map = {}\n",
    "        for col1, col2 in cols_to_swap:\n",
    "            rename_map[col1] = col2\n",
    "            rename_map[col2] = col1\n",
    "    \n",
    "        train_df2 = train_df1.copy()\n",
    "        train_df2 = train_df2.rename(columns=rename_map)\n",
    "        train_df2 = train_df2[train_df1.columns]\n",
    "    \n",
    "        train_df = train_df2\n",
    "        name_f = 'titles_preprocessed_fasttext_rev.pkl'\n",
    "\n",
    "        del train_df1, train_df2\n",
    "        gc.collect()\n",
    "    else:\n",
    "        train_df = train_df1\n",
    "        name_f = 'titles_preprocessed_fasttext.pkl'\n",
    "        \n",
    "        del train_df1\n",
    "        gc.collect()\n",
    "\n",
    "    train_df = train_df.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "    train_df = train_df.sample(len(train_df), random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    text = train_df.progress_apply(prepare, axis=1)\n",
    "    text = [remove_html_tags_and_emoji(t) for t in tqdm(text)]\n",
    "\n",
    "    with open(name_f, 'wb') as write_titles:\n",
    "        pickle.dump(text, write_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b93c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:10.052102Z",
     "iopub.status.busy": "2025-05-02T18:15:10.051808Z",
     "iopub.status.idle": "2025-05-02T18:15:10.062494Z",
     "shell.execute_reply": "2025-05-02T18:15:10.061765Z"
    },
    "papermill": {
     "duration": 0.018001,
     "end_time": "2025-05-02T18:15:10.063801",
     "exception": false,
     "start_time": "2025-05-02T18:15:10.045800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    train_df = pd.read_parquet('../data/preprocessed/train_texts.parquet')\n",
    "    \n",
    "    with open('titles_preprocessed_fasttext_rev.pkl', 'rb') as f:\n",
    "        text = pickle.load(f)\n",
    "\n",
    "    train_df = train_df.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "    train_df = train_df.sample(len(train_df), random_state=42).reset_index(drop=True)\n",
    "    train_df['text'] = text\n",
    "\n",
    "    text = train_df['text']\n",
    "    target = train_df['is_double']\n",
    "    groups = train_df['group_id']\n",
    "\n",
    "    del train_df\n",
    "    gc.collect()\n",
    "\n",
    "    gkf = StratifiedGroupKFold(n_splits=5)\n",
    "    oof_preds = np.zeros(len(text))\n",
    "    \n",
    "    _it = tqdm(enumerate(gkf.split(text, target, groups)), total=5)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in _it:\n",
    "        text_train = [text[i] for i in train_idx]\n",
    "        y_train = [target[i] for i in train_idx]\n",
    "        text_val = [text[i] for i in val_idx]\n",
    "        y_val = [target[i] for i in val_idx]\n",
    "    \n",
    "        train_file = f'train_data_fold{fold}.txt'\n",
    "        # val_file = f'val_data_fold{fold}.txt'\n",
    "        \n",
    "        _it.set_description('writing train to file')\n",
    "        with open(train_file, 'w+', encoding='utf-8') as tr:\n",
    "            for idx in range(len(text_train)):\n",
    "                tr.write('__label__' + str(y_train[idx]) + ' ' + text_train[idx] + '\\n')\n",
    "    \n",
    "        # _it.set_description('writing val to file')\n",
    "        # with open(val_file, 'w+', encoding='utf-8') as valf:\n",
    "        #     for idx in range(len(text_val)):\n",
    "        #         valf.write('__label__' + str(y_val[idx]) + ' ' + text_val[idx] + '\\n')\n",
    "        \n",
    "        _it.set_description('training')\n",
    "        ft_model = fasttext.train_supervised(\n",
    "            input=train_file,\n",
    "            dim=300,\n",
    "        )\n",
    "        _it.set_description('saving model')\n",
    "        ft_model.save_model(f'fast_avito_fold{fold}.model')\n",
    "    \n",
    "        _it.set_description('predicting')\n",
    "        val_preds = []\n",
    "        for text_ in text_val:\n",
    "            pred = ft_model.predict(text_)\n",
    "            val_preds.append(pred[1][0] if pred[0][0][-1] == '1' else 1-pred[1][0])\n",
    "        oof_preds[val_idx] = np.array(val_preds)\n",
    "    \n",
    "        precision, recall, thresholds = precision_recall_curve(y_val, val_preds)\n",
    "        oof_pr_auc = auc(recall, precision)\n",
    "        print(f'for {fold}\\'th fold {oof_pr_auc=}')\n",
    "    \n",
    "        os.remove(train_file)\n",
    "        # os.remove(val_file)\n",
    "\n",
    "        del text_train, y_train, text_val, y_val, ft_model, val_preds\n",
    "        gc.collect()\n",
    "        \n",
    "    _it.close()\n",
    "\n",
    "    with open('oof_preds.pkl', 'wb') as w:\n",
    "        pickle.dump(oof_preds, w)\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(target, oof_preds)\n",
    "    oof_pr_auc = auc(recall, precision)\n",
    "    print(f'{oof_pr_auc=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdf310c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:10.074763Z",
     "iopub.status.busy": "2025-05-02T18:15:10.074446Z",
     "iopub.status.idle": "2025-05-02T18:15:10.083562Z",
     "shell.execute_reply": "2025-05-02T18:15:10.082674Z"
    },
    "papermill": {
     "duration": 0.01641,
     "end_time": "2025-05-02T18:15:10.085008",
     "exception": false,
     "start_time": "2025-05-02T18:15:10.068598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if GET_REV_OOFS:\n",
    "    train_df = pd.read_parquet('../data/preprocessed/train_texts.parquet')\n",
    "    \n",
    "    with open('titles_preprocessed_fasttext_rev.pkl', 'rb') as f:\n",
    "        text = pickle.load(f)\n",
    "\n",
    "    train_df = train_df.sort_values(by=['variantid_1', 'variantid_2'])\n",
    "    train_df = train_df.sample(len(train_df), random_state=42).reset_index(drop=True)\n",
    "    train_df['text'] = text\n",
    "\n",
    "    text = train_df['text']\n",
    "    target = train_df['is_double']\n",
    "    groups = train_df['group_id']\n",
    "\n",
    "    del train_df\n",
    "    gc.collect()\n",
    "\n",
    "    gkf = StratifiedGroupKFold(n_splits=5)\n",
    "    oof_preds_rev = np.zeros(len(text))\n",
    "    \n",
    "    _it = tqdm(enumerate(gkf.split(text, target, groups)), total=5)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in _it:\n",
    "        text_val = [text[i] for i in val_idx]\n",
    "        y_val = [target[i] for i in val_idx]\n",
    "    \n",
    "        _it.set_description('loading model')\n",
    "        ft_model = fasttext.load_model(f'fast_avito_fold{fold}.model')\n",
    "    \n",
    "        _it.set_description('predicting')\n",
    "        val_preds = []\n",
    "        for text_ in text_val:\n",
    "            pred = ft_model.predict(text_)\n",
    "            val_preds.append(pred[1][0] if pred[0][0][-1] == '1' else 1-pred[1][0])\n",
    "        oof_preds_rev[val_idx] = np.array(val_preds)\n",
    "    \n",
    "        precision, recall, thresholds = precision_recall_curve(y_val, val_preds)\n",
    "        oof_pr_auc = auc(recall, precision)\n",
    "        print(f'for {fold}\\'th fold {oof_pr_auc=}')\n",
    "    \n",
    "        os.remove(train_file)\n",
    "\n",
    "        del text_val, y_val, ft_model, val_preds\n",
    "        gc.collect()\n",
    "        \n",
    "    _it.close()\n",
    "\n",
    "    with open('oof_preds_rev.pkl', 'wb') as w:\n",
    "        pickle.dump(oof_preds_rev, w)\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(target, oof_preds_rev)\n",
    "    oof_pr_auc = auc(recall, precision)\n",
    "    print(f'{oof_pr_auc=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4f4c010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:10.095773Z",
     "iopub.status.busy": "2025-05-02T18:15:10.095467Z",
     "iopub.status.idle": "2025-05-02T18:15:10.101391Z",
     "shell.execute_reply": "2025-05-02T18:15:10.100351Z"
    },
    "papermill": {
     "duration": 0.013226,
     "end_time": "2025-05-02T18:15:10.103096",
     "exception": false,
     "start_time": "2025-05-02T18:15:10.089870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_batch_predictions(texts, model_paths):\n",
    "    predictions = np.zeros((len(texts), len(model_paths)))\n",
    "    \n",
    "    for model_idx, path in enumerate(tqdm(model_paths)):\n",
    "        model = fasttext.load_model(path)\n",
    "        for text_idx, text in enumerate(texts):\n",
    "            p = model.predict(text)\n",
    "            predictions[text_idx, model_idx] = p[1][0] if p[0][0][-1] == '1' else 1 - p[1][0]\n",
    "        del model\n",
    "        gc.collect()\n",
    "    avg_predictions = np.mean(predictions, axis=1)\n",
    "    \n",
    "    return avg_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639764f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:15:10.113997Z",
     "iopub.status.busy": "2025-05-02T18:15:10.113645Z",
     "iopub.status.idle": "2025-05-02T18:47:38.064450Z",
     "shell.execute_reply": "2025-05-02T18:47:38.063401Z"
    },
    "papermill": {
     "duration": 1948.587223,
     "end_time": "2025-05-02T18:47:38.695214",
     "exception": false,
     "start_time": "2025-05-02T18:15:10.107991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [24:31<00:00, 339.86it/s]\n",
      "100%|██████████| 500000/500000 [00:25<00:00, 19266.40it/s]\n",
      "100%|██████████| 5/5 [07:16<00:00, 87.20s/it]\n"
     ]
    }
   ],
   "source": [
    "if DO_INFER:\n",
    "    test_df = pd.read_parquet('../data/preprocessed/test_texts.parquet')\n",
    "    test_df = test_df.sort_values(by=['variantid_1', 'variantid_2']).reset_index(drop=True)\n",
    "    \n",
    "    test_texts = test_df.progress_apply(prepare, axis=1)\n",
    "    test_texts_no_emj = test_texts.progress_apply(remove_html_tags_and_emoji)\n",
    "\n",
    "    del test_texts, test_df\n",
    "    gc.collect()\n",
    "\n",
    "    model_paths = [f'fast_avito_fold{i}.model' for i in range(5)]\n",
    "\n",
    "    test_preds = get_batch_predictions(test_texts_no_emj, model_paths)\n",
    "    \n",
    "    with open('test_preds.pkl', 'wb') as w:\n",
    "        pickle.dump(test_preds, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7da2d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T18:47:39.914630Z",
     "iopub.status.busy": "2025-05-02T18:47:39.913783Z",
     "iopub.status.idle": "2025-05-02T19:17:25.431527Z",
     "shell.execute_reply": "2025-05-02T19:17:25.430579Z"
    },
    "papermill": {
     "duration": 1787.33205,
     "end_time": "2025-05-02T19:17:26.596388",
     "exception": false,
     "start_time": "2025-05-02T18:47:39.264338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [21:20<00:00, 390.58it/s]\n",
      "100%|██████████| 500000/500000 [00:26<00:00, 18572.17it/s]\n",
      "100%|██████████| 5/5 [07:44<00:00, 93.00s/it]\n"
     ]
    }
   ],
   "source": [
    "if DO_INFER_REV:\n",
    "    test_df_rev = pd.read_parquet('../data/preprocessed/test_texts.parquet')\n",
    "    test_df_rev = test_df_rev.sort_values(by=['variantid_1', 'variantid_2']).reset_index(drop=True)\n",
    "\n",
    "    cols_to_swap = [\n",
    "        ('variantid_1', 'variantid_2'),\n",
    "        ('name_1', 'name_2'),\n",
    "        ('description_1', 'description_2'),\n",
    "        ('category_level_1_1', 'category_level_1_2'),\n",
    "        ('category_level_2_1', 'category_level_2_2'),\n",
    "        ('category_level_3_1', 'category_level_3_2'),\n",
    "        ('category_level_4_1', 'category_level_4_2'),\n",
    "        ('characteristic_attributes_mapping_1', 'characteristic_attributes_mapping_2')\n",
    "    ]\n",
    "\n",
    "    rename_map = {}\n",
    "    for col1, col2 in cols_to_swap:\n",
    "        rename_map[col1] = col2\n",
    "        rename_map[col2] = col1\n",
    "\n",
    "    test_df_rev = test_df_rev.rename(columns=rename_map)\n",
    "    test_texts_rev = test_df_rev.progress_apply(prepare, axis=1)\n",
    "    test_texts_no_emj_rev = test_texts_rev.progress_apply(remove_html_tags_and_emoji)\n",
    "\n",
    "    del test_texts_rev, test_df_rev\n",
    "    gc.collect()\n",
    "\n",
    "    model_paths = [f'fast_avito_fold{i}.model' for i in range(5)]\n",
    "\n",
    "    test_preds_rev = get_batch_predictions(test_texts_no_emj_rev, model_paths)\n",
    "    \n",
    "    with open('test_preds_rev.pkl', 'wb') as w:\n",
    "        pickle.dump(test_preds_rev, w)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7260659,
     "sourceId": 11579984,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7300547,
     "sourceId": 11640267,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 326571,
     "modelInstanceId": 306125,
     "sourceId": 369850,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 326571,
     "modelInstanceId": 306125,
     "sourceId": 369866,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 326571,
     "modelInstanceId": 306125,
     "sourceId": 370101,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 326571,
     "modelInstanceId": 306125,
     "sourceId": 370102,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3763.049954,
   "end_time": "2025-05-02T19:17:30.748788",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-02T18:14:47.698834",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
