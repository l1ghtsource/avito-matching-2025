{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a17506",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-21T13:55:08.200137Z",
     "iopub.status.busy": "2025-04-21T13:55:08.199832Z",
     "iopub.status.idle": "2025-04-21T13:55:14.656612Z",
     "shell.execute_reply": "2025-04-21T13:55:14.656020Z"
    },
    "papermill": {
     "duration": 6.462513,
     "end_time": "2025-04-21T13:55:14.658017",
     "exception": false,
     "start_time": "2025-04-21T13:55:08.195504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b76ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T13:55:14.664537Z",
     "iopub.status.busy": "2025-04-21T13:55:14.664179Z",
     "iopub.status.idle": "2025-04-21T13:55:26.767138Z",
     "shell.execute_reply": "2025-04-21T13:55:26.766558Z"
    },
    "papermill": {
     "duration": 12.107481,
     "end_time": "2025-04-21T13:55:26.768622",
     "exception": false,
     "start_time": "2025-04-21T13:55:14.661141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\n",
    "    'avito-merge-pairs-and-products/train_df.parquet', \n",
    "    columns=['attr_keys_1', 'attr_keys_2', 'attr_vals_1', 'attr_vals_2', 'group_id', 'action_date', 'is_double']\n",
    ")\n",
    "test = pd.read_parquet(\n",
    "    'avito-merge-pairs-and-products/test_df.parquet',\n",
    "    columns=['attr_keys_1', 'attr_keys_2', 'attr_vals_1', 'attr_vals_2']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a5b75f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T13:55:26.774462Z",
     "iopub.status.busy": "2025-04-21T13:55:26.774203Z",
     "iopub.status.idle": "2025-04-21T13:55:55.849866Z",
     "shell.execute_reply": "2025-04-21T13:55:55.849003Z"
    },
    "papermill": {
     "duration": 29.080169,
     "end_time": "2025-04-21T13:55:55.851449",
     "exception": false,
     "start_time": "2025-04-21T13:55:26.771280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def has_empty(row):\n",
    "    return (\n",
    "        len(row['attr_keys_1']) == 0 or\n",
    "        len(row['attr_vals_1']) == 0 or\n",
    "        len(row['attr_keys_2']) == 0 or\n",
    "        len(row['attr_vals_2']) == 0\n",
    "    )\n",
    "\n",
    "# на инференсе none кидать если []\n",
    "train = train[~train.apply(has_empty, axis=1)]\n",
    "test = test[~test.apply(has_empty, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f157c50c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T13:55:55.857434Z",
     "iopub.status.busy": "2025-04-21T13:55:55.857175Z",
     "iopub.status.idle": "2025-04-21T13:55:55.867079Z",
     "shell.execute_reply": "2025-04-21T13:55:55.866524Z"
    },
    "papermill": {
     "duration": 0.013919,
     "end_time": "2025-04-21T13:55:55.868028",
     "exception": false,
     "start_time": "2025-04-21T13:55:55.854109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttrDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, keys1, vals1, keys2, vals2, targets, \n",
    "        key_vocab=None, val_vocab=None, max_key_len=16, max_val_len=16\n",
    "    ):\n",
    "        self.max_key_len = max_key_len\n",
    "        self.max_val_len = max_val_len\n",
    "        \n",
    "        if key_vocab is None:\n",
    "            unique_keys = set()\n",
    "            for k_list in keys1 + keys2:\n",
    "                unique_keys.update(k_list)\n",
    "            self.key_vocab = {'<pad>': 0}\n",
    "            self.key_vocab.update({k: i + 1 for i, k in enumerate(unique_keys)})\n",
    "        else:\n",
    "            self.key_vocab = key_vocab\n",
    "            \n",
    "        if val_vocab is None:\n",
    "            unique_vals = set()\n",
    "            for v_list in vals1 + vals2:\n",
    "                unique_vals.update(v_list)\n",
    "            self.val_vocab = {'<pad>': 0}\n",
    "            self.val_vocab.update({v: i + 1 for i, v in enumerate(unique_vals)})\n",
    "        else:\n",
    "            self.val_vocab = val_vocab\n",
    "        \n",
    "        self.keys1 = keys1\n",
    "        self.vals1 = vals1\n",
    "        self.keys2 = keys2\n",
    "        self.vals2 = vals2\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        k1 = [self.key_vocab.get(k, 0) for k in self.keys1[idx]]\n",
    "        v1 = [self.val_vocab.get(v, 0) for v in self.vals1[idx]]\n",
    "        k2 = [self.key_vocab.get(k, 0) for k in self.keys2[idx]]\n",
    "        v2 = [self.val_vocab.get(v, 0) for v in self.vals2[idx]]\n",
    "        \n",
    "        k1_padded = k1[:self.max_key_len] + [0] * max(0, self.max_key_len - len(k1))\n",
    "        v1_padded = v1[:self.max_val_len] + [0] * max(0, self.max_val_len - len(v1))\n",
    "        k2_padded = k2[:self.max_key_len] + [0] * max(0, self.max_key_len - len(k2))\n",
    "        v2_padded = v2[:self.max_val_len] + [0] * max(0, self.max_val_len - len(v2))\n",
    "        \n",
    "        k1_mask = torch.BoolTensor([i >= len(k1) for i in range(self.max_key_len)])\n",
    "        v1_mask = torch.BoolTensor([i >= len(v1) for i in range(self.max_val_len)])\n",
    "        k2_mask = torch.BoolTensor([i >= len(k2) for i in range(self.max_key_len)])\n",
    "        v2_mask = torch.BoolTensor([i >= len(v2) for i in range(self.max_val_len)])\n",
    "        \n",
    "        return {\n",
    "            'keys1': torch.LongTensor(k1_padded),\n",
    "            'vals1': torch.LongTensor(v1_padded),\n",
    "            'keys2': torch.LongTensor(k2_padded),\n",
    "            'vals2': torch.LongTensor(v2_padded),\n",
    "            'k1_mask': k1_mask,\n",
    "            'v1_mask': v1_mask,\n",
    "            'k2_mask': k2_mask,\n",
    "            'v2_mask': v2_mask,\n",
    "            'target': torch.FloatTensor([self.targets[idx]])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38f6a473",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T13:55:55.873381Z",
     "iopub.status.busy": "2025-04-21T13:55:55.873153Z",
     "iopub.status.idle": "2025-04-21T13:55:55.877320Z",
     "shell.execute_reply": "2025-04-21T13:55:55.876668Z"
    },
    "papermill": {
     "duration": 0.008238,
     "end_time": "2025-04-21T13:55:55.878548",
     "exception": false,
     "start_time": "2025-04-21T13:55:55.870310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, emb_dim, n_heads):\n",
    "        super(CrossAttention, self).__init__()\n",
    "        self.mh_attn = nn.MultiheadAttention(emb_dim, n_heads, batch_first=True)\n",
    "        \n",
    "    def forward(self, q, k, v, key_padding_mask=None):\n",
    "        attn_output, _ = self.mh_attn(q, k, v, key_padding_mask=key_padding_mask)\n",
    "        return attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e661939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T13:55:55.883729Z",
     "iopub.status.busy": "2025-04-21T13:55:55.883517Z",
     "iopub.status.idle": "2025-04-21T13:55:55.897468Z",
     "shell.execute_reply": "2025-04-21T13:55:55.896764Z"
    },
    "papermill": {
     "duration": 0.017885,
     "end_time": "2025-04-21T13:55:55.898660",
     "exception": false,
     "start_time": "2025-04-21T13:55:55.880775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttrCrossEncoder(nn.Module):\n",
    "    def __init__(self, key_vocab_sz, val_vocab_sz, emb_dim=64, n_heads=4, dropout=0.1):\n",
    "        super(AttrCrossEncoder, self).__init__()\n",
    "        self.key_emb = nn.Embedding(key_vocab_sz, emb_dim, padding_idx=0)\n",
    "        self.val_emb = nn.Embedding(val_vocab_sz, emb_dim, padding_idx=0)\n",
    "        \n",
    "        self.cross_attn = CrossAttention(emb_dim, n_heads)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 4, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1),\n",
    "            # nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, keys1, vals1, keys2, vals2, k1_mask=None, v1_mask=None, k2_mask=None, v2_mask=None):\n",
    "        k1_attn_mask = k1_mask if k1_mask is not None else None\n",
    "        v1_attn_mask = v1_mask if v1_mask is not None else None\n",
    "        k2_attn_mask = k2_mask if k2_mask is not None else None\n",
    "        v2_attn_mask = v2_mask if v2_mask is not None else None\n",
    "        \n",
    "        emb_keys1 = self.key_emb(keys1)\n",
    "        emb_vals1 = self.val_emb(vals1)\n",
    "        emb_keys2 = self.key_emb(keys2)\n",
    "        emb_vals2 = self.val_emb(vals2)\n",
    "        \n",
    "        attn_k1_k2 = self.cross_attn(emb_keys1, emb_keys2, emb_keys2, k2_attn_mask)\n",
    "        attn_k1_v2 = self.cross_attn(emb_keys1, emb_vals2, emb_vals2, v2_attn_mask)\n",
    "        attn_v1_k2 = self.cross_attn(emb_vals1, emb_keys2, emb_keys2, k2_attn_mask)\n",
    "        attn_v1_v2 = self.cross_attn(emb_vals1, emb_vals2, emb_vals2, v2_attn_mask)\n",
    "        \n",
    "        if k1_mask is not None:\n",
    "            mask1 = (~k1_mask).float().unsqueeze(-1)\n",
    "            pooled_k1_k2 = (attn_k1_k2 * mask1).sum(dim=1) / mask1.sum(dim=1).clamp(min=1.0)\n",
    "        else:\n",
    "            pooled_k1_k2 = attn_k1_k2.mean(dim=1)\n",
    "            \n",
    "        if k1_mask is not None:\n",
    "            mask1 = (~k1_mask).float().unsqueeze(-1)\n",
    "            pooled_k1_v2 = (attn_k1_v2 * mask1).sum(dim=1) / mask1.sum(dim=1).clamp(min=1.0)\n",
    "        else:\n",
    "            pooled_k1_v2 = attn_k1_v2.mean(dim=1)\n",
    "            \n",
    "        if v1_mask is not None:\n",
    "            mask1 = (~v1_mask).float().unsqueeze(-1)\n",
    "            pooled_v1_k2 = (attn_v1_k2 * mask1).sum(dim=1) / mask1.sum(dim=1).clamp(min=1.0)\n",
    "        else:\n",
    "            pooled_v1_k2 = attn_v1_k2.mean(dim=1)\n",
    "            \n",
    "        if v1_mask is not None:\n",
    "            mask1 = (~v1_mask).float().unsqueeze(-1)\n",
    "            pooled_v1_v2 = (attn_v1_v2 * mask1).sum(dim=1) / mask1.sum(dim=1).clamp(min=1.0)\n",
    "        else:\n",
    "            pooled_v1_v2 = attn_v1_v2.mean(dim=1)\n",
    "        \n",
    "        concat = torch.cat([pooled_k1_k2, pooled_k1_v2, pooled_v1_k2, pooled_v1_v2], dim=1)\n",
    "        concat = self.dropout(concat)\n",
    "        \n",
    "        out = self.fc(concat)\n",
    "        \n",
    "        return out.squeeze(1)\n",
    "\n",
    "\n",
    "class BabyAttrCrossEncoder(nn.Module):\n",
    "    def __init__(self, key_vocab_sz, val_vocab_sz, emb_dim=64, n_heads=4, dropout=0.1):\n",
    "        super(BabyAttrCrossEncoder, self).__init__()\n",
    "        self.key_emb = nn.Embedding(key_vocab_sz, emb_dim, padding_idx=0)\n",
    "        self.val_emb = nn.Embedding(val_vocab_sz, emb_dim, padding_idx=0)\n",
    "        \n",
    "        self.cross_attn = CrossAttention(emb_dim, n_heads)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, keys1, vals1, keys2, vals2, k1_mask=None, v1_mask=None, k2_mask=None, v2_mask=None):\n",
    "        emb_keys1 = self.key_emb(keys1)\n",
    "        emb_vals1 = self.val_emb(vals1)\n",
    "        emb_vals2 = self.val_emb(vals2)\n",
    "        \n",
    "        group1 = torch.cat([emb_keys1, emb_vals1], dim=1)\n",
    "        group2 = torch.cat([emb_vals1, emb_vals2], dim=1)\n",
    "        \n",
    "        if k1_mask is not None and v1_mask is not None:\n",
    "            g1_mask = torch.cat([k1_mask, v1_mask], dim=1)\n",
    "        else:\n",
    "            g1_mask = None\n",
    "            \n",
    "        if v1_mask is not None and v2_mask is not None:\n",
    "            g2_mask = torch.cat([v1_mask, v2_mask], dim=1)\n",
    "        else:\n",
    "            g2_mask = None\n",
    "        \n",
    "        attn_output = self.cross_attn(group1, group2, group2, g2_mask)\n",
    "        \n",
    "        if g1_mask is not None:\n",
    "            mask = (~g1_mask).float().unsqueeze(-1)\n",
    "            pooled_output = (attn_output * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1.0)\n",
    "        else:\n",
    "            pooled_output = attn_output.mean(dim=1)\n",
    "        \n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        out = self.fc(pooled_output)\n",
    "        \n",
    "        return out.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14724502",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T13:55:55.904889Z",
     "iopub.status.busy": "2025-04-21T13:55:55.904689Z",
     "iopub.status.idle": "2025-04-21T13:55:55.908056Z",
     "shell.execute_reply": "2025-04-21T13:55:55.907402Z"
    },
    "papermill": {
     "duration": 0.006952,
     "end_time": "2025-04-21T13:55:55.909043",
     "exception": false,
     "start_time": "2025-04-21T13:55:55.902091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import Sampler\n",
    "\n",
    "# class LengthGroupedSampler(Sampler):\n",
    "#     def __init__(self, data_source, lengths, batch_size, mega_batch_mult=100):\n",
    "#         self.data_source = data_source\n",
    "#         self.lengths = lengths\n",
    "#         self.batch_size = batch_size\n",
    "#         self.mega_batch_mult = mega_batch_mult\n",
    "#         self.indices = self._create_length_grouped_indices()\n",
    "\n",
    "#     def _create_length_grouped_indices(self):\n",
    "#         indices = np.random.permutation(len(self.lengths))\n",
    "        \n",
    "#         mega_batch_size = self.batch_size * self.mega_batch_mult\n",
    "#         mega_batches = [indices[i:i + mega_batch_size] for i in range(0, len(indices), mega_batch_size)]\n",
    "\n",
    "#         sorted_indices = []\n",
    "#         for mega_batch in mega_batches:\n",
    "#             sorted_mega_batch = sorted(mega_batch, key=lambda i: self.lengths[i], reverse=True)\n",
    "#             sorted_indices.extend(sorted_mega_batch)\n",
    "\n",
    "#         return sorted_indices\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         for i in range(0, len(self.indices), self.batch_size):\n",
    "#             yield self.indices[i:i + self.batch_size]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return (len(self.indices) + self.batch_size - 1) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e02f4be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T13:55:55.914264Z",
     "iopub.status.busy": "2025-04-21T13:55:55.914064Z",
     "iopub.status.idle": "2025-04-21T13:55:55.931794Z",
     "shell.execute_reply": "2025-04-21T13:55:55.931111Z"
    },
    "papermill": {
     "duration": 0.021697,
     "end_time": "2025-04-21T13:55:55.932876",
     "exception": false,
     "start_time": "2025-04-21T13:55:55.911179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_with_groupkfold(\n",
    "    df, n_splits=5, max_key_len=16, max_val_len=16, batch_size=4096, \n",
    "    num_epochs=10, lr=0.001, device='cuda'\n",
    "):\n",
    "    groups = df['group_id'].values\n",
    "    targets = df['is_double'].values\n",
    "\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    oof_preds = np.zeros(len(df))\n",
    "    oof_targets = targets.copy()\n",
    "\n",
    "    fold_metrics_prauc = []\n",
    "    fold_models = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(gkf.split(df, targets, groups)):\n",
    "        print(f'fold {fold+1}/{n_splits}')\n",
    "        train_df = df.iloc[train_idx]\n",
    "        val_df = df.iloc[val_idx]\n",
    "\n",
    "        train_dataset = AttrDataset(\n",
    "            keys1=train_df['attr_keys_1'].tolist(),\n",
    "            vals1=train_df['attr_vals_1'].tolist(),\n",
    "            keys2=train_df['attr_keys_2'].tolist(),\n",
    "            vals2=train_df['attr_vals_2'].tolist(),\n",
    "            targets=train_df['is_double'].tolist(),\n",
    "            max_key_len=max_key_len,\n",
    "            max_val_len=max_val_len\n",
    "        )\n",
    "\n",
    "        val_dataset = AttrDataset(\n",
    "            keys1=val_df['attr_keys_1'].tolist(),\n",
    "            vals1=val_df['attr_vals_1'].tolist(),\n",
    "            keys2=val_df['attr_keys_2'].tolist(),\n",
    "            vals2=val_df['attr_vals_2'].tolist(),\n",
    "            targets=val_df['is_double'].tolist(),\n",
    "            key_vocab=train_dataset.key_vocab,\n",
    "            val_vocab=train_dataset.val_vocab,\n",
    "            max_key_len=max_key_len,\n",
    "            max_val_len=max_val_len\n",
    "        )\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "        model_params = {\n",
    "            'key_vocab_sz': len(train_dataset.key_vocab),\n",
    "            'val_vocab_sz': len(train_dataset.val_vocab),\n",
    "            'emb_dim': 64,\n",
    "            'n_heads': 4,\n",
    "            'dropout': 0.2,\n",
    "            'key_vocab': train_dataset.key_vocab,\n",
    "            'val_vocab': train_dataset.val_vocab\n",
    "        }\n",
    "\n",
    "        model = BabyAttrCrossEncoder(\n",
    "            key_vocab_sz=model_params['key_vocab_sz'],\n",
    "            val_vocab_sz=model_params['val_vocab_sz'],\n",
    "            emb_dim=model_params['emb_dim'],\n",
    "            n_heads=model_params['n_heads'],\n",
    "            dropout=model_params['dropout']\n",
    "        )\n",
    "\n",
    "        device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        model = model.to(device)\n",
    "\n",
    "        pos_weight = torch.tensor([2574371 / 110662]).to(device)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
    "\n",
    "        best_val_prauc = 0.0\n",
    "        best_model_state = None\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_preds = []\n",
    "            train_targets = []\n",
    "\n",
    "            for batch in tqdm(train_loader, desc=f'train epoch {epoch+1}/{num_epochs}'):\n",
    "                keys1 = batch['keys1'].to(device)\n",
    "                vals1 = batch['vals1'].to(device)\n",
    "                keys2 = batch['keys2'].to(device)\n",
    "                vals2 = batch['vals2'].to(device)\n",
    "                k1_mask = batch['k1_mask'].to(device)\n",
    "                v1_mask = batch['v1_mask'].to(device)\n",
    "                k2_mask = batch['k2_mask'].to(device)\n",
    "                v2_mask = batch['v2_mask'].to(device)\n",
    "                targets_batch = batch['target'].squeeze(1).to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(keys1, vals1, keys2, vals2, k1_mask, v1_mask, k2_mask, v2_mask)\n",
    "                loss = criterion(outputs, targets_batch)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                train_preds.extend(outputs.detach().cpu().numpy())\n",
    "                train_targets.extend(targets_batch.cpu().numpy())\n",
    "\n",
    "            train_prauc = average_precision_score(train_targets, train_preds)\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_preds = []\n",
    "            val_targets = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(val_loader, desc=f'val epoch {epoch+1}/{num_epochs}'):\n",
    "                    keys1 = batch['keys1'].to(device)\n",
    "                    vals1 = batch['vals1'].to(device)\n",
    "                    keys2 = batch['keys2'].to(device)\n",
    "                    vals2 = batch['vals2'].to(device)\n",
    "                    k1_mask = batch['k1_mask'].to(device)\n",
    "                    v1_mask = batch['v1_mask'].to(device)\n",
    "                    k2_mask = batch['k2_mask'].to(device)\n",
    "                    v2_mask = batch['v2_mask'].to(device)\n",
    "                    targets_batch = batch['target'].squeeze(1).to(device)\n",
    "\n",
    "                    outputs = model(keys1, vals1, keys2, vals2, k1_mask, v1_mask, k2_mask, v2_mask)\n",
    "                    loss = criterion(outputs, targets_batch)\n",
    "\n",
    "                    val_loss += loss.item()\n",
    "                    val_preds.extend(outputs.cpu().numpy())\n",
    "                    val_targets.extend(targets_batch.cpu().numpy())\n",
    "\n",
    "            val_prauc = average_precision_score(val_targets, val_preds)\n",
    "            \n",
    "            scheduler.step(val_prauc)\n",
    "\n",
    "            if val_prauc > best_val_prauc:\n",
    "                best_val_prauc = val_prauc\n",
    "                best_model_state = model.state_dict().copy()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
    "                  f\"Train PR-AUC: {train_prauc:.4f}, \"\n",
    "                  f\"Val Loss: {val_loss/len(val_loader):.4f}, Val PR-AUC: {val_prauc:.4f}\")\n",
    "\n",
    "        torch.save({\n",
    "            'model_state_dict': best_model_state,\n",
    "            'key_vocab': train_dataset.key_vocab,\n",
    "            'val_vocab': train_dataset.val_vocab,\n",
    "            'model_params': model_params,\n",
    "            'fold': fold,\n",
    "            'val_prauc': best_val_prauc,\n",
    "        }, f'attrcrossencoder_fold{fold+1}.pt')\n",
    "\n",
    "        model.load_state_dict(best_model_state)\n",
    "        model.eval()\n",
    "        fold_models.append({\n",
    "            'model': model,\n",
    "            'key_vocab': train_dataset.key_vocab,\n",
    "            'val_vocab': train_dataset.val_vocab\n",
    "        })\n",
    "\n",
    "        val_fold_preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                keys1 = batch['keys1'].to(device)\n",
    "                vals1 = batch['vals1'].to(device)\n",
    "                keys2 = batch['keys2'].to(device)\n",
    "                vals2 = batch['vals2'].to(device)\n",
    "                k1_mask = batch['k1_mask'].to(device)\n",
    "                v1_mask = batch['v1_mask'].to(device)\n",
    "                k2_mask = batch['k2_mask'].to(device)\n",
    "                v2_mask = batch['v2_mask'].to(device)\n",
    "\n",
    "                outputs = model(keys1, vals1, keys2, vals2, k1_mask, v1_mask, k2_mask, v2_mask)\n",
    "                val_fold_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "        oof_preds[val_idx] = val_fold_preds\n",
    "        fold_metrics_prauc.append(best_val_prauc)\n",
    "        \n",
    "        print(f\"fold {fold+1} finished, best val prauc: {best_val_prauc:.4f}\")\n",
    "\n",
    "    oof_prauc = average_precision_score(oof_targets, oof_preds)\n",
    "    oof_binary_preds = (oof_preds >= 0.5).astype(int)\n",
    "    oof_accuracy = accuracy_score(oof_targets, oof_binary_preds)\n",
    "    oof_precision, oof_recall, oof_f1, _ = precision_recall_fscore_support(\n",
    "        oof_targets, oof_binary_preds, average='binary'\n",
    "    )\n",
    "    \n",
    "    print(f\"{oof_prauc=}\")\n",
    "    print(f\"{oof_accuracy=}\")\n",
    "    print(f\"{oof_precision=}\")\n",
    "    print(f\"{oof_recall=}\")\n",
    "    print(f\"{oof_f1=}\")\n",
    "    \n",
    "    print(f\"\\nfolds mean prauc{np.mean(fold_metrics_prauc):.4f}, std: {np.std(fold_metrics_prauc):.4f}\")\n",
    "    \n",
    "    oof_results = {\n",
    "        'oof_preds': oof_preds,\n",
    "        'oof_targets': oof_targets,\n",
    "        'oof_metrics': {\n",
    "            'prauc': oof_prauc,\n",
    "            'accuracy': oof_accuracy,\n",
    "            'precision': oof_precision,\n",
    "            'recall': oof_recall,\n",
    "            'f1': oof_f1\n",
    "        },\n",
    "        'fold_metrics_prauc': fold_metrics_prauc,\n",
    "    }\n",
    "    \n",
    "    return oof_results, fold_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "388aa8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T13:55:55.937743Z",
     "iopub.status.busy": "2025-04-21T13:55:55.937559Z",
     "iopub.status.idle": "2025-04-21T18:17:53.324140Z",
     "shell.execute_reply": "2025-04-21T18:17:53.323420Z"
    },
    "papermill": {
     "duration": 15717.390526,
     "end_time": "2025-04-21T18:17:53.325524",
     "exception": false,
     "start_time": "2025-04-21T13:55:55.934998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 1/10: 100%|██████████| 525/525 [04:09<00:00,  2.11it/s]\n",
      "val epoch 1/10: 100%|██████████| 132/132 [00:56<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.9282, Train PR-AUC: 0.2533, Val Loss: 0.7976, Val PR-AUC: 0.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 2/10: 100%|██████████| 525/525 [04:10<00:00,  2.09it/s]\n",
      "val epoch 2/10: 100%|██████████| 132/132 [00:56<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.7396, Train PR-AUC: 0.3733, Val Loss: 0.7712, Val PR-AUC: 0.1718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 3/10: 100%|██████████| 525/525 [04:10<00:00,  2.10it/s]\n",
      "val epoch 3/10: 100%|██████████| 132/132 [00:56<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.6347, Train PR-AUC: 0.4490, Val Loss: 0.8114, Val PR-AUC: 0.1643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 4/10: 100%|██████████| 525/525 [04:10<00:00,  2.10it/s]\n",
      "val epoch 4/10: 100%|██████████| 132/132 [00:56<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.5496, Train PR-AUC: 0.5104, Val Loss: 0.9265, Val PR-AUC: 0.1590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 5/10: 100%|██████████| 525/525 [04:10<00:00,  2.09it/s]\n",
      "val epoch 5/10: 100%|██████████| 132/132 [00:56<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.4747, Train PR-AUC: 0.5685, Val Loss: 1.0228, Val PR-AUC: 0.1420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 6/10: 100%|██████████| 525/525 [04:10<00:00,  2.10it/s]\n",
      "val epoch 6/10: 100%|██████████| 132/132 [00:56<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.4397, Train PR-AUC: 0.5953, Val Loss: 1.1358, Val PR-AUC: 0.1530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 7/10: 100%|██████████| 525/525 [04:09<00:00,  2.10it/s]\n",
      "val epoch 7/10: 100%|██████████| 132/132 [00:56<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.4101, Train PR-AUC: 0.6182, Val Loss: 1.2620, Val PR-AUC: 0.1389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 8/10: 100%|██████████| 525/525 [04:09<00:00,  2.10it/s]\n",
      "val epoch 8/10: 100%|██████████| 132/132 [00:56<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.3795, Train PR-AUC: 0.6420, Val Loss: 1.3532, Val PR-AUC: 0.1510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 9/10: 100%|██████████| 525/525 [04:10<00:00,  2.10it/s]\n",
      "val epoch 9/10: 100%|██████████| 132/132 [00:55<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.3667, Train PR-AUC: 0.6512, Val Loss: 1.4462, Val PR-AUC: 0.1430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 10/10: 100%|██████████| 525/525 [04:09<00:00,  2.11it/s]\n",
      "val epoch 10/10: 100%|██████████| 132/132 [00:56<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.3549, Train PR-AUC: 0.6610, Val Loss: 1.4921, Val PR-AUC: 0.1466\n",
      "fold 1 finished, best val prauc: 0.1726\n",
      "fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 1/10: 100%|██████████| 525/525 [04:09<00:00,  2.10it/s]\n",
      "val epoch 1/10: 100%|██████████| 132/132 [00:57<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.8696, Train PR-AUC: 0.2487, Val Loss: 1.0699, Val PR-AUC: 0.2050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 2/10: 100%|██████████| 525/525 [04:08<00:00,  2.11it/s]\n",
      "val epoch 2/10: 100%|██████████| 132/132 [00:57<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.6879, Train PR-AUC: 0.3621, Val Loss: 1.1200, Val PR-AUC: 0.2087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 3/10: 100%|██████████| 525/525 [04:08<00:00,  2.11it/s]\n",
      "val epoch 3/10: 100%|██████████| 132/132 [00:56<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.5851, Train PR-AUC: 0.4368, Val Loss: 1.2180, Val PR-AUC: 0.2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 4/10: 100%|██████████| 525/525 [04:08<00:00,  2.12it/s]\n",
      "val epoch 4/10: 100%|██████████| 132/132 [00:56<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.5015, Train PR-AUC: 0.5011, Val Loss: 1.5097, Val PR-AUC: 0.1778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 5/10: 100%|██████████| 525/525 [04:08<00:00,  2.11it/s]\n",
      "val epoch 5/10: 100%|██████████| 132/132 [00:56<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.4310, Train PR-AUC: 0.5567, Val Loss: 1.7862, Val PR-AUC: 0.1598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 6/10: 100%|██████████| 525/525 [04:09<00:00,  2.11it/s]\n",
      "val epoch 6/10: 100%|██████████| 132/132 [00:56<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.3658, Train PR-AUC: 0.6103, Val Loss: 1.9401, Val PR-AUC: 0.1589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 7/10: 100%|██████████| 525/525 [04:08<00:00,  2.11it/s]\n",
      "val epoch 7/10: 100%|██████████| 132/132 [00:56<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.3391, Train PR-AUC: 0.6320, Val Loss: 2.1969, Val PR-AUC: 0.1409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 8/10: 100%|██████████| 525/525 [04:06<00:00,  2.13it/s]\n",
      "val epoch 8/10: 100%|██████████| 132/132 [00:56<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.3163, Train PR-AUC: 0.6528, Val Loss: 2.3189, Val PR-AUC: 0.1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 9/10: 100%|██████████| 525/525 [04:07<00:00,  2.12it/s]\n",
      "val epoch 9/10: 100%|██████████| 132/132 [00:56<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.2911, Train PR-AUC: 0.6746, Val Loss: 2.4569, Val PR-AUC: 0.1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 10/10: 100%|██████████| 525/525 [04:09<00:00,  2.11it/s]\n",
      "val epoch 10/10: 100%|██████████| 132/132 [00:57<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.2806, Train PR-AUC: 0.6833, Val Loss: 2.5652, Val PR-AUC: 0.1334\n",
      "fold 2 finished, best val prauc: 0.2087\n",
      "fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 1/10: 100%|██████████| 525/525 [04:07<00:00,  2.12it/s]\n",
      "val epoch 1/10: 100%|██████████| 132/132 [00:57<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.8579, Train PR-AUC: 0.2493, Val Loss: 1.1551, Val PR-AUC: 0.1784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 2/10: 100%|██████████| 525/525 [04:08<00:00,  2.11it/s]\n",
      "val epoch 2/10: 100%|██████████| 132/132 [00:57<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.6889, Train PR-AUC: 0.3659, Val Loss: 1.1623, Val PR-AUC: 0.1755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 3/10: 100%|██████████| 525/525 [04:07<00:00,  2.12it/s]\n",
      "val epoch 3/10: 100%|██████████| 132/132 [00:57<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.5888, Train PR-AUC: 0.4463, Val Loss: 1.2572, Val PR-AUC: 0.1611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 4/10: 100%|██████████| 525/525 [04:08<00:00,  2.11it/s]\n",
      "val epoch 4/10: 100%|██████████| 132/132 [00:57<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.5057, Train PR-AUC: 0.5142, Val Loss: 1.2944, Val PR-AUC: 0.1619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 5/10: 100%|██████████| 525/525 [04:08<00:00,  2.11it/s]\n",
      "val epoch 5/10: 100%|██████████| 132/132 [00:57<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.4321, Train PR-AUC: 0.5782, Val Loss: 1.5759, Val PR-AUC: 0.1528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 6/10: 100%|██████████| 525/525 [04:07<00:00,  2.12it/s]\n",
      "val epoch 6/10: 100%|██████████| 132/132 [00:57<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.3984, Train PR-AUC: 0.6040, Val Loss: 1.6444, Val PR-AUC: 0.1556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 7/10: 100%|██████████| 525/525 [04:08<00:00,  2.11it/s]\n",
      "val epoch 7/10: 100%|██████████| 132/132 [00:57<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.3698, Train PR-AUC: 0.6276, Val Loss: 1.7158, Val PR-AUC: 0.1479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 8/10: 100%|██████████| 525/525 [04:06<00:00,  2.13it/s]\n",
      "val epoch 8/10: 100%|██████████| 132/132 [00:57<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.3402, Train PR-AUC: 0.6521, Val Loss: 1.9502, Val PR-AUC: 0.1469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 9/10: 100%|██████████| 525/525 [04:06<00:00,  2.13it/s]\n",
      "val epoch 9/10: 100%|██████████| 132/132 [00:57<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.3277, Train PR-AUC: 0.6624, Val Loss: 1.9582, Val PR-AUC: 0.1472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 10/10: 100%|██████████| 525/525 [04:06<00:00,  2.13it/s]\n",
      "val epoch 10/10: 100%|██████████| 132/132 [00:57<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.3167, Train PR-AUC: 0.6717, Val Loss: 1.9704, Val PR-AUC: 0.1446\n",
      "fold 3 finished, best val prauc: 0.1784\n",
      "fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 1/10: 100%|██████████| 525/525 [04:07<00:00,  2.12it/s]\n",
      "val epoch 1/10: 100%|██████████| 132/132 [00:57<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.8679, Train PR-AUC: 0.2445, Val Loss: 1.0661, Val PR-AUC: 0.1671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 2/10: 100%|██████████| 525/525 [04:07<00:00,  2.12it/s]\n",
      "val epoch 2/10: 100%|██████████| 132/132 [00:56<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.6997, Train PR-AUC: 0.3655, Val Loss: 1.1464, Val PR-AUC: 0.1586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 3/10: 100%|██████████| 525/525 [04:06<00:00,  2.13it/s]\n",
      "val epoch 3/10: 100%|██████████| 132/132 [00:57<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.6024, Train PR-AUC: 0.4432, Val Loss: 1.2465, Val PR-AUC: 0.1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 4/10: 100%|██████████| 525/525 [04:06<00:00,  2.13it/s]\n",
      "val epoch 4/10: 100%|██████████| 132/132 [00:57<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.5197, Train PR-AUC: 0.5092, Val Loss: 1.3453, Val PR-AUC: 0.1394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 5/10: 100%|██████████| 525/525 [04:06<00:00,  2.13it/s]\n",
      "val epoch 5/10: 100%|██████████| 132/132 [00:57<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.4467, Train PR-AUC: 0.5680, Val Loss: 1.4880, Val PR-AUC: 0.1346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 6/10: 100%|██████████| 525/525 [04:07<00:00,  2.13it/s]\n",
      "val epoch 6/10: 100%|██████████| 132/132 [00:56<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.4130, Train PR-AUC: 0.5948, Val Loss: 1.5663, Val PR-AUC: 0.1336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 7/10: 100%|██████████| 525/525 [04:06<00:00,  2.13it/s]\n",
      "val epoch 7/10: 100%|██████████| 132/132 [00:56<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.3842, Train PR-AUC: 0.6191, Val Loss: 1.6516, Val PR-AUC: 0.1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 8/10: 100%|██████████| 525/525 [04:06<00:00,  2.13it/s]\n",
      "val epoch 8/10: 100%|██████████| 132/132 [00:57<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.3556, Train PR-AUC: 0.6412, Val Loss: 1.8258, Val PR-AUC: 0.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 9/10: 100%|██████████| 525/525 [04:06<00:00,  2.13it/s]\n",
      "val epoch 9/10: 100%|██████████| 132/132 [00:57<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.3431, Train PR-AUC: 0.6526, Val Loss: 1.8555, Val PR-AUC: 0.1263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 10/10: 100%|██████████| 525/525 [04:06<00:00,  2.13it/s]\n",
      "val epoch 10/10: 100%|██████████| 132/132 [00:58<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.3315, Train PR-AUC: 0.6615, Val Loss: 1.9665, Val PR-AUC: 0.1212\n",
      "fold 4 finished, best val prauc: 0.1671\n",
      "fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 1/10: 100%|██████████| 525/525 [04:06<00:00,  2.13it/s]\n",
      "val epoch 1/10: 100%|██████████| 132/132 [00:56<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.8600, Train PR-AUC: 0.2392, Val Loss: 1.0499, Val PR-AUC: 0.2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 2/10: 100%|██████████| 525/525 [04:06<00:00,  2.13it/s]\n",
      "val epoch 2/10: 100%|██████████| 132/132 [00:56<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.6840, Train PR-AUC: 0.3585, Val Loss: 1.1495, Val PR-AUC: 0.1951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 3/10: 100%|██████████| 525/525 [04:07<00:00,  2.12it/s]\n",
      "val epoch 3/10: 100%|██████████| 132/132 [00:57<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.5886, Train PR-AUC: 0.4333, Val Loss: 1.2715, Val PR-AUC: 0.1945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 4/10: 100%|██████████| 525/525 [04:07<00:00,  2.12it/s]\n",
      "val epoch 4/10: 100%|██████████| 132/132 [00:57<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.5088, Train PR-AUC: 0.5007, Val Loss: 1.4137, Val PR-AUC: 0.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 5/10: 100%|██████████| 525/525 [04:07<00:00,  2.12it/s]\n",
      "val epoch 5/10: 100%|██████████| 132/132 [00:57<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.4367, Train PR-AUC: 0.5619, Val Loss: 1.6004, Val PR-AUC: 0.1720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 6/10: 100%|██████████| 525/525 [04:08<00:00,  2.11it/s]\n",
      "val epoch 6/10: 100%|██████████| 132/132 [00:57<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.4039, Train PR-AUC: 0.5894, Val Loss: 1.8323, Val PR-AUC: 0.1617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 7/10: 100%|██████████| 525/525 [04:08<00:00,  2.11it/s]\n",
      "val epoch 7/10: 100%|██████████| 132/132 [00:57<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.3757, Train PR-AUC: 0.6122, Val Loss: 1.9504, Val PR-AUC: 0.1633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 8/10: 100%|██████████| 525/525 [04:07<00:00,  2.12it/s]\n",
      "val epoch 8/10: 100%|██████████| 132/132 [00:57<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.3463, Train PR-AUC: 0.6368, Val Loss: 2.0853, Val PR-AUC: 0.1534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 9/10: 100%|██████████| 525/525 [04:08<00:00,  2.11it/s]\n",
      "val epoch 9/10: 100%|██████████| 132/132 [00:58<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.3347, Train PR-AUC: 0.6472, Val Loss: 2.1216, Val PR-AUC: 0.1520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 10/10: 100%|██████████| 525/525 [04:10<00:00,  2.10it/s]\n",
      "val epoch 10/10: 100%|██████████| 132/132 [00:57<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.3228, Train PR-AUC: 0.6572, Val Loss: 2.2841, Val PR-AUC: 0.1445\n",
      "fold 5 finished, best val prauc: 0.2026\n",
      "oof_prauc=0.13450917686914585\n",
      "oof_accuracy=0.7555326135656433\n",
      "oof_precision=0.09671350261669452\n",
      "oof_recall=0.591332164609351\n",
      "oof_f1=0.16623839833146825\n",
      "\n",
      "folds mean prauc0.1859, std: 0.0166\n"
     ]
    }
   ],
   "source": [
    "oof_results, fold_models = train_with_groupkfold(train, n_splits=5, max_key_len=16, max_val_len=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cadf8986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T18:17:56.032478Z",
     "iopub.status.busy": "2025-04-21T18:17:56.032034Z",
     "iopub.status.idle": "2025-04-21T18:17:56.040972Z",
     "shell.execute_reply": "2025-04-21T18:17:56.040419Z"
    },
    "papermill": {
     "duration": 1.30708,
     "end_time": "2025-04-21T18:17:56.042112",
     "exception": false,
     "start_time": "2025-04-21T18:17:54.735032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensemble_predict(\n",
    "    fold_models, keys1, vals1, keys2, vals2, \n",
    "    max_key_len=16, max_val_len=16, device='cuda'\n",
    "):\n",
    "    all_preds = []\n",
    "    \n",
    "    for model_data in fold_models:\n",
    "        model = model_data['model']\n",
    "        key_vocab = model_data['key_vocab']\n",
    "        val_vocab = model_data['val_vocab']\n",
    "        \n",
    "        k1 = [key_vocab.get(k, 0) for k in keys1]\n",
    "        v1 = [val_vocab.get(v, 0) for v in vals1]\n",
    "        k2 = [key_vocab.get(k, 0) for k in keys2]\n",
    "        v2 = [val_vocab.get(v, 0) for v in vals2]\n",
    "        \n",
    "        k1_padded = k1[:max_key_len] + [0] * max(0, max_key_len - len(k1))\n",
    "        v1_padded = v1[:max_val_len] + [0] * max(0, max_val_len - len(v1))\n",
    "        k2_padded = k2[:max_key_len] + [0] * max(0, max_key_len - len(k2))\n",
    "        v2_padded = v2[:max_val_len] + [0] * max(0, max_val_len - len(v2))\n",
    "        \n",
    "        k1_mask = torch.BoolTensor([i >= len(k1) for i in range(max_key_len)])\n",
    "        v1_mask = torch.BoolTensor([i >= len(v1) for i in range(max_val_len)])\n",
    "        k2_mask = torch.BoolTensor([i >= len(k2) for i in range(max_key_len)])\n",
    "        v2_mask = torch.BoolTensor([i >= len(v2) for i in range(max_val_len)])\n",
    "        \n",
    "        device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        keys1_tensor = torch.LongTensor([k1_padded]).to(device)\n",
    "        vals1_tensor = torch.LongTensor([v1_padded]).to(device)\n",
    "        keys2_tensor = torch.LongTensor([k2_padded]).to(device)\n",
    "        vals2_tensor = torch.LongTensor([v2_padded]).to(device)\n",
    "        \n",
    "        k1_mask = k1_mask.to(device)\n",
    "        v1_mask = v1_mask.to(device)\n",
    "        k2_mask = k2_mask.to(device)\n",
    "        v2_mask = v2_mask.to(device)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = model(\n",
    "                keys1_tensor, vals1_tensor, keys2_tensor, vals2_tensor, \n",
    "                k1_mask, v1_mask, k2_mask, v2_mask\n",
    "            )\n",
    "            all_preds.append(pred.item())\n",
    "    \n",
    "    ensemble_pred = np.mean(all_preds)\n",
    "    \n",
    "    return ensemble_pred"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 235012277,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15777.109723,
   "end_time": "2025-04-21T18:18:01.174285",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-21T13:55:04.064562",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
