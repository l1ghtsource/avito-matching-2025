# Avito ML Cup 2025

_MISIS Neychev Loss team_

Team Members:

1. **Рыжичкин Кирилл** - ML Engineer
2. **Аксеновский Максим** - ML Engineer
3. **Герасин Тимофей** - ML Engineer
4. **Груздев Александр** - ML Engineer
      
## Кейс "Поиск дублей"

> Цель соревнования заключалась в разработке алгоритма для идентификации дублирующихся объявлений о товарах на платформе Avito. Необходимо было для каждой пары товаров предсказать, являются ли они дубликатами.

### Базовые признаки

- Мэтч по категориям 1-4 уровня, частичный мэтч по 4 уровню, полнота столбцов
- Частичные мэтчи по названиям и описаниям, BM25, TF-IDF, LCP, LCS, сходства для строк и списков (IOU по n-gram, overlap и др.), антислова, отношения и разницы длин
- Совпадения для словаря атрибутов, топ-атрибуты по категориям
- Отношения и абсолютные разницы процентов некорректных ("битых") слов
- Признаки на основе ROUGE-метрик для текстов
    
### Очистка текста

- Обнаружена проблема: 97% слов содержали смешанные русские и английские буквы схожего начертания
- Решение: Использовали `kenlm` для исправления раскладки. На инференсе считали перплексию для вариантов en→ru и ru→en и выбирали лучший, если в слове смешаны языки
    
### Картиночные признаки

- Использование предобученных моделей:
      - Marqo-SigLIP (доменная модель)
      - marqo-ecommerce-embeddings-L
      - Модель из топ-5 решения соревнования Kaggle 'Shopee - Price Match Guarantee' (обученная с ArcFace loss)
- Дообучение собственной модели:
      - Модель: `timm/resnet50.a1_in1k`
      - Метод обучения: Contrastive loss (OCL показал себя хуже)
      - Результат: 0.19 PRAUC на валидации, выше всех предыдущих картиночных претрейнов

### DL для текстов

- Использование предобученных моделей:
      - `sergeyzh/BERTA`: косинусное сходство для строк (название + категория + описание)
      - `multilingual-e5-large-instruct`
      - `userbge-m3`
- Обучение FastText:
      - На объединенных описаниях товаров
      - Test Time Augmentation (TTA) значительно улучшило скор
- Дообучение собственной DL-модели:
      - Модель: `rubert-base` на конкатенации признаков товаров
      - Test Time Augmentation (TTA) значительно улучшило скор

### Моделирование

- LightAutoML (LAMA):
      - Использовалась как для общей модели, так и в блендах с категориальными
- Модели по категориям:
      - Обучены отдельные модели CatBoost для каждой из 7 категорий товаров первого уровня
      - Блендинг: `0.5 * общая_модель + 0.5 * категориальная_модель`
- Финальный ансамбль (один из вариантов):
      - Бленд `0.5 * lama_full + 0.5 * (0.7 * cb_cat1 + 0.3 * lama_cat1)`

### Постпроцессинг

- Алаймент вероятностей:
      - Вероятности категориальных моделей выравнивались под общую модель LAMA
      - Формула: `p_adj = (p1 * pi1 * rho0) / (p1 * pi1 * rho0 + (1 - p1) * pi0 * rho1)`
- Ручная корректировка:
      - Вероятности для некоторых категорий домножались на коэффициенты (например, для животных и электроники на 1.2, для транспорта на 1.3)

### Результаты

| Этап                                  | CV Score | LB Score |
| :------------------------------------ | :---------- | :---------- |
| Начальный подход (до фикса бага)     | 0.487       | 0.339       |
| После фикса бага                      | 0.523       | 0.348       |
| LAMA + категории как фичи            | 0.569       | 0.392       |
| + Новые фичи + Marqo-SigLIP           | 0.589       | 0.401       |
| + BERTA                               | 0.600       | 0.410       |
| + marqo-ecommerce-embeddings-L        | 0.601       | 0.413       |
| + FastText с TTA                      | 0.611       | 0.423       |
| + Shopee Image Model                  | 0.612       | 0.425       |
| + multilingual-e5-large-instruct    | 0.615       | 0.427       |
| + Модели по категориям (блендинг)     | -           | 0.436       |
| + Замена общего CB на LAMA в бленде   | -           | 0.442       |
| + Свой Text (rubert) и Image (resnet50) DL + TTA | 0.626+      | 0.455       |
| + Постпроцессинг (алаймент)           | -           | 0.465       |
| + Постпроцессинг (ручной)             | -           | **0.471**   |

### Не сработало

- TabM: Хорошо показал себя соло (0.4222 LB), но не улучшил общий бленд
- Обучение жирных текстовых и картиночных моделей (долго + не хватает ресурсов)
- Постпроцессинг пар (id1, id2) и (id2, id1) не дал прироста
- Обучение LAMA для отдельных категорий не улучшило общую метрику
- Псевдолейблинг
- Online Contrastive Loss (OCL) работал хуже обычного Contrastive Loss
- Модели по категориям 2-го уровня ухудшали скор
- Отбор признаков (использовали все ~470)
- Разметка новых категорий с помощью LLM/VLM

### Не успели

- Расширение датасета транзитивными цепочками
- Интеграция кросс-энкодера на атрибутах (давал 0.2 PRAUC соло)
- Обучение моделей по кластерам пользователей
- Обучение больших LLM/VLM (требовало слишком много времени)
